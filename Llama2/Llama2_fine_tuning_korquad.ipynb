{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkwith7/aSSIST_ML/blob/main/Llama2/Llama2_fine_tuning_korquad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama 2를 KorQuad 데이터셋에 맞게 fine-tuning 하기\n",
        "### References:\n",
        "1.   https://www.youtube.com/watch?v=LslC2nKEEGU\n",
        "2.   https://colab.research.google.com/drive/1JDnGJbxT8fSqwnXY8J-XFo73AtiSuQMe?usp=sharing"
      ],
      "metadata": {
        "id": "9oUv-sq7dqVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2sSeBHAffPi",
        "outputId": "15914138-09e1-4c25-ed35-f2e04e75a6d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 24 01:10:52 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0              44W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoTrain Advanced\n",
        "https://github.com/huggingface/autotrain-advanced"
      ],
      "metadata": {
        "id": "sDwNw4-1dzJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSs7uo21QY2J",
        "outputId": "d5324abf-e71b-466d-fb83-baeb088c8570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q autotrain-advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch 업데이트"
      ],
      "metadata": {
        "id": "vq_pCl2AeAkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain setup --update-torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RoZi2-uRPPE",
        "outputId": "4831d7a1-5e98-4823-c426-0647e9f0e3d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Korquad 데이터셋에 맞게 Llama2 Fine-Tuning\n",
        "- 학습 데이터 디랙터리 \"korquad_prompt_da\"를 만들고 학습데이터 korquad_data_augmented.json를 디렉터리에 업로드\n",
        "- autotrain 설정값: https://github.com/huggingface/autotrain-advanced/blob/f1367b590dfc53d240e9684779991da540590386/src/autotrain/cli/run_llm.py#L21 (**과거 버전[0.6.35]**)\n",
        "- autotrain 설정값: https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/cli/run_llm.py#L17 (**최신 버전[0.6.80]**)\n"
      ],
      "metadata": {
        "id": "eQ2KBBcseFQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation 적용 x\n",
        "# !autotrain llm --train \\\n",
        "#     --project_name \"llama2-korquad-finetuning\" \\\n",
        "#     --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
        "#     --data_path \"korquad_prompt\" \\\n",
        "#     --text_column \"text\" \\\n",
        "#     --use_peft \\\n",
        "#     --use_int4 \\\n",
        "#     --learning_rate 2e-4 \\\n",
        "#     --train_batch_size 4 \\\n",
        "#     --num_train_epochs 100 \\\n",
        "#     --trainer sft \\\n",
        "#     --model_max_length 256\n",
        "# Data Augmentation 적용 o (과거 버전)[0.6.35]\n",
        "# !autotrain llm --train \\\n",
        "#     --project_name \"llama2-korquad-finetuning-da\" \\\n",
        "#     --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
        "#     --data_path \"korquad_prompt_da\" \\\n",
        "#     --text_column \"text\" \\\n",
        "#     --use_peft \\\n",
        "#     --use_int4 \\\n",
        "#     --learning_rate 2e-4 \\\n",
        "#     --train_batch_size 8 \\\n",
        "#     --num_train_epochs 40 \\\n",
        "#     --trainer sft \\\n",
        "#     --model_max_length 256\n",
        "# Data Augmentation 적용 o (최신 버전)[0.6.80]\n",
        "!autotrain llm --train \\\n",
        "    --project-name \"llama2-korquad-finetuning-da\" \\\n",
        "    --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
        "    --data-path \"korquad_prompt_da\" \\\n",
        "    --text-column \"text\" \\\n",
        "    --peft \\\n",
        "    --quantization \"int4\" \\\n",
        "    --lr 2e-4 \\\n",
        "    --batch-size 8 \\\n",
        "    --epochs 40 \\\n",
        "    --trainer sft \\\n",
        "    --model_max_length 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8Hu-Annh0d-",
        "outputId": "71001022-4251-40a2-fff0-f9387a10529f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=-1, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization='int4', model_max_length=256, trainer='sft', target_modules=None, merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, apply_chat_template=False, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token=None, repo_id=None, push_to_hub=False, model='TinyPixel/Llama-2-7B-bf16-sharded', project_name='llama2-korquad-finetuning-da', seed=42, epochs=40, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='korquad_prompt_da', train_split='train', valid_split=None, batch_size=8, func=<function run_llm_command_factory at 0x7805769f57e0>)\u001b[0m\n",
            "> \u001b[1mINFO    Starting local training...\u001b[0m\n",
            "> \u001b[1mINFO    {\"model\":\"TinyPixel/Llama-2-7B-bf16-sharded\",\"project_name\":\"llama2-korquad-finetuning-da\",\"data_path\":\"korquad_prompt_da\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":-1,\"model_max_length\":256,\"padding\":null,\"trainer\":\"sft\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0002,\"epochs\":40,\"batch_size\":8,\"warmup_ratio\":0.1,\"gradient_accumulation\":1,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.0,\"max_grad_norm\":1.0,\"seed\":42,\"apply_chat_template\":false,\"quantization\":\"int4\",\"target_modules\":null,\"merge_adapter\":false,\"peft\":true,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"prompt\",\"text_column\":\"text\",\"rejected_text_column\":\"rejected\",\"push_to_hub\":false,\"repo_id\":null,\"username\":null,\"token\":null}\u001b[0m\n",
            "> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'llama2-korquad-finetuning-da/training_params.json']\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 9446.63it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1510.92it/s]\n",
            "Generating train split: 220 examples [00:00, 12032.64 examples/s]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-24 01:13:18\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 220\n",
            "})\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-24 01:13:18\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "tokenizer_config.json: 100% 676/676 [00:00<00:00, 4.49MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 11.0MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 23.3MB/s]\n",
            "special_tokens_map.json: 100% 411/411 [00:00<00:00, 2.97MB/s]\n",
            "config.json: 100% 626/626 [00:00<00:00, 3.67MB/s]\n",
            "model.safetensors.index.json: 100% 28.1k/28.1k [00:00<00:00, 100MB/s]\n",
            "Downloading shards:   0% 0/14 [00:00<?, ?it/s]\n",
            "model-00001-of-00014.safetensors:   0% 0.00/981M [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   2% 21.0M/981M [00:00<00:05, 160MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   4% 41.9M/981M [00:00<00:05, 174MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   6% 62.9M/981M [00:00<00:05, 182MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   9% 83.9M/981M [00:00<00:04, 187MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  11% 105M/981M [00:00<00:04, 189MB/s] \u001b[A\n",
            "model-00001-of-00014.safetensors:  13% 126M/981M [00:00<00:04, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  15% 147M/981M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  17% 168M/981M [00:00<00:04, 199MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  19% 189M/981M [00:00<00:03, 200MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  21% 210M/981M [00:01<00:03, 201MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  24% 231M/981M [00:01<00:03, 197MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  26% 252M/981M [00:01<00:03, 195MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  28% 273M/981M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  30% 294M/981M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  32% 315M/981M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  34% 336M/981M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  36% 357M/981M [00:01<00:03, 192MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  38% 377M/981M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  41% 398M/981M [00:02<00:03, 192MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  43% 419M/981M [00:02<00:02, 190MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  45% 440M/981M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  47% 461M/981M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  49% 482M/981M [00:02<00:02, 198MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  51% 503M/981M [00:02<00:02, 195MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  53% 524M/981M [00:02<00:02, 198MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  56% 545M/981M [00:02<00:02, 200MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  58% 566M/981M [00:02<00:02, 198MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  60% 587M/981M [00:03<00:02, 196MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  62% 608M/981M [00:03<00:01, 196MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  64% 629M/981M [00:03<00:01, 195MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  67% 661M/981M [00:03<00:01, 199MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  69% 682M/981M [00:03<00:01, 197MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  72% 703M/981M [00:03<00:01, 196MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  74% 724M/981M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  76% 744M/981M [00:03<00:01, 192MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  78% 765M/981M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  80% 786M/981M [00:04<00:01, 193MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  82% 807M/981M [00:04<00:00, 195MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  84% 828M/981M [00:04<00:00, 192MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  87% 849M/981M [00:04<00:00, 191MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  89% 870M/981M [00:04<00:00, 190MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  91% 891M/981M [00:04<00:00, 187MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  93% 912M/981M [00:04<00:00, 188MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  95% 933M/981M [00:04<00:00, 189MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  97% 954M/981M [00:04<00:00, 189MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors: 100% 981M/981M [00:05<00:00, 193MB/s]\n",
            "Downloading shards:   7% 1/14 [00:05<01:08,  5.24s/it]\n",
            "model-00002-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   3% 31.5M/967M [00:00<00:04, 204MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   5% 52.4M/967M [00:00<00:04, 198MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   8% 73.4M/967M [00:00<00:04, 193MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  10% 94.4M/967M [00:00<00:04, 194MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  12% 115M/967M [00:00<00:04, 193MB/s] \u001b[A\n",
            "model-00002-of-00014.safetensors:  14% 136M/967M [00:00<00:04, 190MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  16% 157M/967M [00:00<00:04, 188MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  18% 178M/967M [00:00<00:04, 189MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  21% 199M/967M [00:01<00:04, 186MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  23% 220M/967M [00:01<00:04, 183MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  25% 241M/967M [00:01<00:04, 178MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  27% 262M/967M [00:01<00:03, 177MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  29% 283M/967M [00:01<00:03, 173MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  31% 304M/967M [00:01<00:03, 171MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  34% 325M/967M [00:01<00:03, 172MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  36% 346M/967M [00:01<00:03, 178MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  38% 367M/967M [00:02<00:03, 181MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  40% 388M/967M [00:02<00:03, 181MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  42% 409M/967M [00:02<00:03, 177MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  44% 430M/967M [00:02<00:03, 179MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  47% 451M/967M [00:02<00:02, 178MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  49% 472M/967M [00:02<00:02, 178MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  51% 493M/967M [00:02<00:02, 178MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  53% 514M/967M [00:02<00:02, 177MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  55% 535M/967M [00:02<00:02, 175MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  57% 556M/967M [00:03<00:02, 176MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  60% 577M/967M [00:03<00:02, 176MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  62% 598M/967M [00:03<00:02, 172MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  64% 619M/967M [00:03<00:01, 176MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  66% 640M/967M [00:03<00:01, 175MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  68% 661M/967M [00:03<00:01, 171MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  70% 682M/967M [00:03<00:01, 171MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  73% 703M/967M [00:03<00:01, 172MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  75% 724M/967M [00:04<00:01, 171MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  77% 744M/967M [00:04<00:01, 171MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  79% 765M/967M [00:04<00:01, 168MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  81% 786M/967M [00:04<00:01, 176MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  84% 807M/967M [00:04<00:00, 180MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  86% 828M/967M [00:04<00:00, 187MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  88% 849M/967M [00:04<00:00, 187MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  90% 870M/967M [00:04<00:00, 188MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  92% 891M/967M [00:04<00:00, 190MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  94% 912M/967M [00:05<00:00, 192MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  97% 933M/967M [00:05<00:00, 193MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors: 100% 967M/967M [00:05<00:00, 181MB/s]\n",
            "Downloading shards:  14% 2/14 [00:10<01:04,  5.40s/it]\n",
            "model-00003-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   2% 21.0M/967M [00:00<00:04, 202MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   4% 41.9M/967M [00:00<00:04, 204MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   7% 62.9M/967M [00:00<00:04, 199MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 203MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  11% 105M/967M [00:00<00:04, 201MB/s] \u001b[A\n",
            "model-00003-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 201MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 198MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 197MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  20% 189M/967M [00:00<00:04, 194MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  22% 210M/967M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  24% 231M/967M [00:01<00:03, 195MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  26% 252M/967M [00:01<00:03, 195MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  28% 273M/967M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  30% 294M/967M [00:01<00:03, 197MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  33% 315M/967M [00:01<00:03, 197MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  35% 336M/967M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  37% 357M/967M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  39% 377M/967M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  41% 398M/967M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  43% 419M/967M [00:02<00:02, 190MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  46% 440M/967M [00:02<00:02, 189MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  48% 461M/967M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  50% 482M/967M [00:02<00:02, 178MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  52% 503M/967M [00:02<00:03, 149MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  54% 524M/967M [00:02<00:03, 146MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  56% 545M/967M [00:02<00:02, 154MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  59% 566M/967M [00:03<00:02, 161MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  61% 587M/967M [00:03<00:02, 169MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  63% 608M/967M [00:03<00:02, 175MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  65% 629M/967M [00:03<00:01, 182MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  67% 650M/967M [00:03<00:01, 184MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  69% 671M/967M [00:03<00:01, 185MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  72% 692M/967M [00:03<00:01, 185MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  74% 713M/967M [00:03<00:01, 188MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  76% 734M/967M [00:03<00:01, 188MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  78% 755M/967M [00:04<00:01, 189MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  80% 776M/967M [00:04<00:01, 189MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  82% 797M/967M [00:04<00:00, 193MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  85% 818M/967M [00:04<00:01, 119MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  87% 839M/967M [00:04<00:00, 135MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  89% 860M/967M [00:04<00:00, 147MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  91% 881M/967M [00:04<00:00, 157MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  93% 902M/967M [00:05<00:00, 168MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  95% 923M/967M [00:05<00:00, 173MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  98% 944M/967M [00:05<00:00, 176MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors: 100% 967M/967M [00:05<00:00, 179MB/s]\n",
            "Downloading shards:  21% 3/14 [00:16<00:59,  5.43s/it]\n",
            "model-00004-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   3% 31.5M/990M [00:00<00:04, 209MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   5% 52.4M/990M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   7% 73.4M/990M [00:00<00:04, 197MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  10% 94.4M/990M [00:00<00:04, 193MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  12% 115M/990M [00:00<00:04, 194MB/s] \u001b[A\n",
            "model-00004-of-00014.safetensors:  14% 136M/990M [00:00<00:04, 197MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  16% 157M/990M [00:00<00:04, 193MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  18% 178M/990M [00:00<00:04, 193MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  20% 199M/990M [00:01<00:04, 175MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  22% 220M/990M [00:01<00:04, 177MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  24% 241M/990M [00:01<00:04, 179MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  26% 262M/990M [00:01<00:03, 186MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  29% 283M/990M [00:01<00:03, 191MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  31% 304M/990M [00:01<00:03, 188MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  33% 325M/990M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  35% 346M/990M [00:01<00:03, 192MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  37% 367M/990M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  39% 388M/990M [00:02<00:03, 195MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  41% 409M/990M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  43% 430M/990M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  46% 451M/990M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  48% 472M/990M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  51% 503M/990M [00:02<00:02, 196MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  53% 524M/990M [00:02<00:02, 197MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  55% 545M/990M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  57% 566M/990M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  59% 587M/990M [00:03<00:02, 194MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  61% 608M/990M [00:03<00:01, 192MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  64% 629M/990M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  66% 650M/990M [00:03<00:01, 177MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  68% 671M/990M [00:03<00:01, 162MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  70% 692M/990M [00:03<00:01, 160MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  72% 713M/990M [00:03<00:01, 165MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  74% 734M/990M [00:03<00:01, 167MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  76% 755M/990M [00:04<00:01, 154MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  78% 776M/990M [00:04<00:01, 156MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  81% 797M/990M [00:04<00:01, 164MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  83% 818M/990M [00:04<00:01, 169MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  85% 839M/990M [00:04<00:00, 172MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  87% 860M/990M [00:04<00:00, 174MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  89% 881M/990M [00:04<00:00, 178MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  91% 902M/990M [00:04<00:00, 182MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  93% 923M/990M [00:05<00:00, 184MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  95% 944M/990M [00:05<00:00, 187MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  97% 965M/990M [00:05<00:00, 186MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors: 100% 990M/990M [00:05<00:00, 183MB/s]\n",
            "Downloading shards:  29% 4/14 [00:21<00:55,  5.51s/it]\n",
            "model-00005-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   2% 21.0M/944M [00:00<00:04, 196MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   4% 41.9M/944M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   7% 62.9M/944M [00:00<00:04, 200MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   9% 83.9M/944M [00:00<00:04, 198MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  11% 105M/944M [00:00<00:04, 198MB/s] \u001b[A\n",
            "model-00005-of-00014.safetensors:  13% 126M/944M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  16% 147M/944M [00:00<00:04, 189MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  18% 168M/944M [00:00<00:04, 190MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  20% 189M/944M [00:00<00:03, 192MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  22% 210M/944M [00:01<00:03, 191MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  24% 231M/944M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  27% 252M/944M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  29% 273M/944M [00:01<00:03, 192MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  31% 294M/944M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  33% 315M/944M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  36% 336M/944M [00:01<00:03, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  38% 357M/944M [00:01<00:03, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  40% 377M/944M [00:01<00:02, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  42% 398M/944M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  44% 419M/944M [00:02<00:02, 196MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  47% 440M/944M [00:02<00:02, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  49% 461M/944M [00:02<00:02, 196MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  51% 482M/944M [00:02<00:02, 197MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  53% 503M/944M [00:02<00:02, 197MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  56% 524M/944M [00:02<00:02, 196MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  58% 545M/944M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  60% 566M/944M [00:02<00:01, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  62% 587M/944M [00:03<00:01, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  64% 608M/944M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  67% 629M/944M [00:03<00:01, 196MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  69% 650M/944M [00:03<00:01, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  71% 671M/944M [00:03<00:01, 185MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  73% 692M/944M [00:03<00:01, 186MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  76% 713M/944M [00:03<00:01, 188MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  78% 734M/944M [00:03<00:01, 189MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  80% 755M/944M [00:03<00:00, 189MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  82% 776M/944M [00:04<00:00, 192MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  84% 797M/944M [00:04<00:00, 185MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  87% 818M/944M [00:04<00:00, 186MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  89% 839M/944M [00:04<00:00, 186MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  91% 860M/944M [00:04<00:00, 186MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  93% 881M/944M [00:04<00:00, 174MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  96% 902M/944M [00:04<00:00, 177MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  98% 923M/944M [00:04<00:00, 179MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors: 100% 944M/944M [00:04<00:00, 190MB/s]\n",
            "Downloading shards:  36% 5/14 [00:26<00:48,  5.37s/it]\n",
            "model-00006-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   1% 10.5M/990M [00:00<00:12, 76.3MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   3% 31.5M/990M [00:00<00:07, 121MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:   5% 52.4M/990M [00:00<00:06, 149MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   7% 73.4M/990M [00:00<00:05, 162MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  10% 94.4M/990M [00:00<00:05, 173MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  12% 115M/990M [00:00<00:04, 180MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:  14% 136M/990M [00:00<00:04, 185MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  16% 157M/990M [00:00<00:04, 190MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  18% 178M/990M [00:01<00:04, 190MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  20% 199M/990M [00:01<00:04, 190MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  22% 220M/990M [00:01<00:04, 189MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  24% 241M/990M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  26% 262M/990M [00:01<00:03, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  29% 283M/990M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  31% 304M/990M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  33% 325M/990M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  35% 346M/990M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  37% 367M/990M [00:02<00:03, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  39% 388M/990M [00:02<00:03, 191MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  41% 409M/990M [00:02<00:03, 193MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  43% 430M/990M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  46% 451M/990M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  48% 472M/990M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  50% 493M/990M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  52% 514M/990M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  54% 535M/990M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  56% 556M/990M [00:02<00:02, 191MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  58% 577M/990M [00:03<00:02, 191MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  60% 598M/990M [00:03<00:02, 191MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  62% 619M/990M [00:03<00:01, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  65% 640M/990M [00:03<00:01, 193MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  67% 661M/990M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  69% 682M/990M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  71% 703M/990M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  73% 724M/990M [00:03<00:01, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  75% 744M/990M [00:03<00:01, 191MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  77% 765M/990M [00:04<00:01, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  79% 786M/990M [00:04<00:01, 190MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  82% 807M/990M [00:04<00:00, 188MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  84% 828M/990M [00:04<00:00, 187MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  86% 849M/990M [00:04<00:00, 187MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  88% 870M/990M [00:04<00:00, 187MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  90% 891M/990M [00:04<00:00, 176MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  92% 912M/990M [00:04<00:00, 182MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  94% 933M/990M [00:05<00:00, 183MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  96% 954M/990M [00:05<00:00, 186MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors: 100% 990M/990M [00:05<00:00, 186MB/s]\n",
            "Downloading shards:  43% 6/14 [00:32<00:42,  5.37s/it]\n",
            "model-00007-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   2% 21.0M/967M [00:00<00:04, 202MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   4% 41.9M/967M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   7% 62.9M/967M [00:00<00:04, 192MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 190MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  11% 105M/967M [00:00<00:04, 190MB/s] \u001b[A\n",
            "model-00007-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 193MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 188MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  17% 168M/967M [00:00<00:05, 149MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  20% 189M/967M [00:01<00:04, 157MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  22% 210M/967M [00:01<00:04, 161MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  24% 231M/967M [00:01<00:04, 166MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  26% 252M/967M [00:01<00:04, 172MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  28% 273M/967M [00:01<00:04, 170MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  30% 294M/967M [00:01<00:03, 176MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  33% 315M/967M [00:01<00:03, 175MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  35% 336M/967M [00:01<00:03, 177MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  37% 357M/967M [00:02<00:03, 178MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  39% 377M/967M [00:02<00:03, 177MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  41% 398M/967M [00:02<00:03, 180MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  43% 419M/967M [00:02<00:03, 182MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  46% 440M/967M [00:02<00:02, 187MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  48% 461M/967M [00:02<00:02, 187MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  50% 482M/967M [00:02<00:02, 186MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  52% 503M/967M [00:02<00:02, 189MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  54% 524M/967M [00:02<00:02, 190MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  56% 545M/967M [00:03<00:02, 189MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  59% 566M/967M [00:03<00:02, 190MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  61% 587M/967M [00:03<00:02, 188MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  63% 608M/967M [00:03<00:01, 187MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  65% 629M/967M [00:03<00:01, 190MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  67% 650M/967M [00:03<00:01, 191MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  69% 671M/967M [00:03<00:01, 190MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  72% 692M/967M [00:03<00:01, 190MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  74% 713M/967M [00:03<00:01, 191MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  76% 734M/967M [00:04<00:01, 192MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  78% 755M/967M [00:04<00:01, 190MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  80% 776M/967M [00:04<00:00, 195MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  82% 797M/967M [00:04<00:00, 179MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  85% 818M/967M [00:04<00:00, 176MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  87% 839M/967M [00:04<00:00, 179MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  89% 860M/967M [00:04<00:00, 118MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  91% 881M/967M [00:05<00:00, 133MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  93% 902M/967M [00:05<00:00, 146MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  97% 933M/967M [00:05<00:00, 165MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors: 100% 967M/967M [00:05<00:00, 176MB/s]\n",
            "Downloading shards:  50% 7/14 [00:38<00:38,  5.47s/it]\n",
            "model-00008-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   3% 31.5M/967M [00:00<00:04, 203MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   5% 52.4M/967M [00:00<00:04, 196MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   8% 73.4M/967M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  10% 94.4M/967M [00:00<00:04, 191MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  12% 115M/967M [00:00<00:04, 192MB/s] \u001b[A\n",
            "model-00008-of-00014.safetensors:  14% 136M/967M [00:00<00:04, 194MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  16% 157M/967M [00:00<00:04, 191MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  18% 178M/967M [00:00<00:04, 188MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  21% 199M/967M [00:01<00:04, 189MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  23% 220M/967M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  25% 241M/967M [00:01<00:03, 185MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  27% 262M/967M [00:01<00:03, 184MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  29% 283M/967M [00:01<00:03, 186MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  31% 304M/967M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  34% 325M/967M [00:01<00:03, 188MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  36% 346M/967M [00:01<00:03, 176MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  38% 367M/967M [00:01<00:03, 165MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  40% 388M/967M [00:02<00:03, 156MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  42% 409M/967M [00:02<00:03, 146MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  44% 430M/967M [00:02<00:03, 150MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  47% 451M/967M [00:02<00:03, 160MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  49% 472M/967M [00:02<00:03, 156MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  51% 493M/967M [00:02<00:02, 166MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  53% 514M/967M [00:02<00:02, 173MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  55% 535M/967M [00:03<00:02, 179MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  57% 556M/967M [00:03<00:02, 182MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  60% 577M/967M [00:03<00:02, 185MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  62% 598M/967M [00:03<00:02, 181MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  64% 619M/967M [00:03<00:01, 187MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  66% 640M/967M [00:03<00:01, 167MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  68% 661M/967M [00:03<00:02, 149MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  70% 682M/967M [00:04<00:02, 112MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  73% 703M/967M [00:04<00:02, 114MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  75% 724M/967M [00:04<00:01, 126MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  77% 744M/967M [00:04<00:01, 132MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  79% 765M/967M [00:04<00:01, 147MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  81% 786M/967M [00:04<00:01, 160MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  84% 807M/967M [00:04<00:00, 171MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  86% 828M/967M [00:04<00:00, 179MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  88% 849M/967M [00:05<00:00, 180MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  90% 870M/967M [00:05<00:00, 183MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  92% 891M/967M [00:05<00:00, 185MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  94% 912M/967M [00:05<00:00, 184MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  97% 933M/967M [00:05<00:00, 189MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors: 100% 967M/967M [00:05<00:00, 170MB/s]\n",
            "Downloading shards:  57% 8/14 [00:43<00:33,  5.60s/it]\n",
            "model-00009-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   2% 21.0M/990M [00:00<00:05, 190MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   4% 41.9M/990M [00:00<00:05, 184MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   6% 62.9M/990M [00:00<00:05, 177MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   8% 83.9M/990M [00:00<00:05, 180MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  11% 105M/990M [00:00<00:04, 187MB/s] \u001b[A\n",
            "model-00009-of-00014.safetensors:  13% 126M/990M [00:00<00:04, 188MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  15% 147M/990M [00:00<00:04, 188MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  17% 168M/990M [00:00<00:04, 191MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  19% 189M/990M [00:01<00:04, 185MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  21% 210M/990M [00:01<00:04, 191MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  23% 231M/990M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  25% 252M/990M [00:01<00:03, 186MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  28% 273M/990M [00:01<00:03, 188MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  30% 294M/990M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  32% 315M/990M [00:01<00:03, 183MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  34% 336M/990M [00:01<00:03, 180MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  36% 357M/990M [00:02<00:04, 135MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  38% 377M/990M [00:02<00:04, 142MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  40% 398M/990M [00:02<00:04, 145MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  42% 419M/990M [00:02<00:03, 152MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  44% 440M/990M [00:02<00:03, 159MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  47% 461M/990M [00:02<00:03, 160MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  49% 482M/990M [00:02<00:03, 165MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  51% 503M/990M [00:02<00:02, 168MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  53% 524M/990M [00:03<00:02, 170MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  55% 545M/990M [00:03<00:02, 172MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  57% 566M/990M [00:03<00:02, 173MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  59% 587M/990M [00:03<00:02, 173MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  61% 608M/990M [00:03<00:02, 174MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  64% 629M/990M [00:03<00:02, 173MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  66% 650M/990M [00:03<00:01, 173MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  68% 671M/990M [00:03<00:01, 175MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  70% 692M/990M [00:04<00:01, 175MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  72% 713M/990M [00:04<00:01, 175MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  74% 734M/990M [00:04<00:01, 175MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  76% 755M/990M [00:04<00:01, 175MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  78% 776M/990M [00:04<00:01, 175MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  81% 797M/990M [00:04<00:01, 172MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  83% 818M/990M [00:04<00:01, 169MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  85% 839M/990M [00:04<00:00, 170MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  87% 860M/990M [00:05<00:00, 152MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  89% 881M/990M [00:05<00:00, 150MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  91% 902M/990M [00:05<00:00, 158MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  93% 923M/990M [00:05<00:00, 162MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  95% 944M/990M [00:05<00:00, 169MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  97% 965M/990M [00:05<00:00, 171MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors: 100% 990M/990M [00:05<00:00, 171MB/s]\n",
            "Downloading shards:  64% 9/14 [00:49<00:28,  5.71s/it]\n",
            "model-00010-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   2% 21.0M/944M [00:00<00:04, 205MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   4% 41.9M/944M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   7% 62.9M/944M [00:00<00:04, 198MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   9% 83.9M/944M [00:00<00:04, 193MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  11% 105M/944M [00:00<00:04, 188MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  13% 126M/944M [00:00<00:05, 163MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  16% 147M/944M [00:01<00:07, 112MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  18% 168M/944M [00:01<00:06, 126MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  20% 189M/944M [00:01<00:05, 143MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  22% 210M/944M [00:01<00:04, 157MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  24% 231M/944M [00:01<00:04, 166MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  27% 252M/944M [00:01<00:04, 164MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  29% 273M/944M [00:01<00:04, 164MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  31% 294M/944M [00:01<00:03, 170MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  33% 315M/944M [00:01<00:03, 178MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  36% 336M/944M [00:02<00:03, 176MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  38% 357M/944M [00:02<00:03, 162MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  40% 377M/944M [00:02<00:05, 95.1MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  42% 398M/944M [00:02<00:04, 112MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  44% 419M/944M [00:02<00:04, 128MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  47% 440M/944M [00:02<00:03, 142MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  49% 461M/944M [00:03<00:03, 154MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  51% 482M/944M [00:03<00:02, 163MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  53% 503M/944M [00:03<00:02, 171MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  56% 524M/944M [00:03<00:02, 176MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  58% 545M/944M [00:03<00:02, 179MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  60% 566M/944M [00:03<00:02, 179MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  62% 587M/944M [00:03<00:01, 186MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  64% 608M/944M [00:03<00:01, 190MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  67% 629M/944M [00:03<00:01, 190MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  69% 650M/944M [00:04<00:01, 191MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  71% 671M/944M [00:04<00:01, 191MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  73% 692M/944M [00:04<00:01, 193MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  76% 713M/944M [00:04<00:01, 193MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  78% 734M/944M [00:04<00:01, 192MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  80% 755M/944M [00:04<00:00, 195MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  82% 776M/944M [00:04<00:00, 193MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  84% 797M/944M [00:04<00:00, 189MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  87% 818M/944M [00:04<00:00, 188MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  89% 839M/944M [00:05<00:00, 188MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  91% 860M/944M [00:05<00:00, 184MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  93% 881M/944M [00:05<00:00, 186MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  96% 902M/944M [00:05<00:00, 187MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  98% 923M/944M [00:05<00:00, 186MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors: 100% 944M/944M [00:05<00:00, 168MB/s]\n",
            "Downloading shards:  71% 10/14 [00:55<00:23,  5.76s/it]\n",
            "model-00011-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   2% 21.0M/990M [00:00<00:05, 178MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   4% 41.9M/990M [00:00<00:06, 150MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   6% 62.9M/990M [00:00<00:05, 165MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   8% 83.9M/990M [00:00<00:05, 170MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  11% 105M/990M [00:00<00:04, 178MB/s] \u001b[A\n",
            "model-00011-of-00014.safetensors:  13% 126M/990M [00:00<00:04, 183MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  15% 147M/990M [00:00<00:04, 170MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  17% 168M/990M [00:01<00:06, 129MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  19% 189M/990M [00:01<00:05, 139MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  21% 210M/990M [00:01<00:05, 147MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  23% 231M/990M [00:01<00:04, 156MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  25% 252M/990M [00:01<00:04, 163MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  28% 273M/990M [00:01<00:04, 172MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  30% 294M/990M [00:01<00:03, 175MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  32% 315M/990M [00:01<00:03, 178MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  34% 336M/990M [00:02<00:03, 179MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  36% 357M/990M [00:02<00:03, 177MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  38% 377M/990M [00:02<00:03, 176MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  40% 398M/990M [00:02<00:03, 176MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  42% 419M/990M [00:02<00:03, 177MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  44% 440M/990M [00:02<00:03, 177MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  47% 461M/990M [00:02<00:02, 178MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  49% 482M/990M [00:02<00:02, 183MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  51% 503M/990M [00:02<00:02, 180MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  53% 524M/990M [00:03<00:02, 182MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  55% 545M/990M [00:03<00:02, 180MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  57% 566M/990M [00:03<00:02, 180MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  59% 587M/990M [00:03<00:02, 179MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  61% 608M/990M [00:03<00:02, 176MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  64% 629M/990M [00:03<00:02, 176MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  66% 650M/990M [00:03<00:01, 174MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  68% 671M/990M [00:03<00:01, 179MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  70% 692M/990M [00:04<00:01, 185MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  72% 713M/990M [00:04<00:01, 191MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  74% 734M/990M [00:04<00:01, 190MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  76% 755M/990M [00:04<00:01, 190MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  78% 776M/990M [00:04<00:01, 174MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  81% 797M/990M [00:04<00:01, 178MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  83% 818M/990M [00:04<00:00, 181MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  85% 839M/990M [00:04<00:00, 188MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  87% 860M/990M [00:04<00:00, 188MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  89% 881M/990M [00:05<00:00, 190MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  91% 902M/990M [00:05<00:00, 190MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  93% 923M/990M [00:05<00:00, 192MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  95% 944M/990M [00:05<00:00, 193MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  97% 965M/990M [00:05<00:00, 192MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors: 100% 990M/990M [00:05<00:00, 177MB/s]\n",
            "Downloading shards:  79% 11/14 [01:01<00:17,  5.76s/it]\n",
            "model-00012-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   2% 21.0M/967M [00:00<00:05, 174MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   4% 41.9M/967M [00:00<00:06, 146MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   7% 62.9M/967M [00:00<00:06, 148MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   9% 83.9M/967M [00:00<00:06, 146MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  11% 105M/967M [00:00<00:05, 161MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  13% 126M/967M [00:00<00:05, 148MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  15% 147M/967M [00:00<00:05, 143MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  17% 168M/967M [00:01<00:05, 140MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  20% 189M/967M [00:01<00:05, 153MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  22% 210M/967M [00:01<00:05, 141MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  24% 231M/967M [00:01<00:05, 129MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  26% 252M/967M [00:01<00:05, 120MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  28% 273M/967M [00:02<00:05, 116MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  30% 294M/967M [00:02<00:05, 130MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  33% 315M/967M [00:02<00:06, 107MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  35% 336M/967M [00:02<00:05, 111MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  37% 357M/967M [00:02<00:06, 96.7MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  39% 377M/967M [00:03<00:05, 101MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  41% 398M/967M [00:03<00:05, 112MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  43% 419M/967M [00:03<00:05, 106MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  46% 440M/967M [00:03<00:04, 113MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  48% 461M/967M [00:03<00:04, 120MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  50% 482M/967M [00:03<00:03, 134MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  52% 503M/967M [00:04<00:03, 127MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  54% 524M/967M [00:04<00:03, 119MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  56% 545M/967M [00:04<00:03, 113MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  59% 566M/967M [00:04<00:03, 128MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  61% 587M/967M [00:04<00:03, 119MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  63% 608M/967M [00:04<00:03, 113MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  65% 629M/967M [00:05<00:02, 115MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  67% 650M/967M [00:05<00:02, 109MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  69% 671M/967M [00:05<00:02, 126MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  72% 692M/967M [00:05<00:02, 123MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  74% 713M/967M [00:05<00:02, 103MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  76% 734M/967M [00:06<00:02, 104MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  78% 755M/967M [00:06<00:01, 119MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  80% 776M/967M [00:06<00:01, 134MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  82% 797M/967M [00:06<00:01, 132MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  85% 818M/967M [00:06<00:01, 124MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  87% 839M/967M [00:06<00:00, 136MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  89% 860M/967M [00:06<00:00, 147MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  91% 881M/967M [00:07<00:00, 158MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  93% 902M/967M [00:07<00:00, 169MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  95% 923M/967M [00:07<00:00, 176MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  98% 944M/967M [00:07<00:00, 182MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors: 100% 967M/967M [00:07<00:00, 129MB/s]\n",
            "Downloading shards:  86% 12/14 [01:09<00:12,  6.31s/it]\n",
            "model-00013-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   2% 21.0M/967M [00:00<00:05, 185MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   4% 41.9M/967M [00:00<00:04, 190MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   7% 62.9M/967M [00:00<00:04, 188MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 186MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  11% 105M/967M [00:00<00:04, 185MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 187MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 189MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 191MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  20% 189M/967M [00:00<00:04, 191MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  22% 210M/967M [00:01<00:03, 192MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  24% 231M/967M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  26% 252M/967M [00:01<00:03, 195MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  28% 273M/967M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  30% 294M/967M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  33% 315M/967M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  35% 336M/967M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  37% 357M/967M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  39% 377M/967M [00:01<00:02, 197MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  41% 398M/967M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  43% 419M/967M [00:02<00:02, 196MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  46% 440M/967M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  48% 461M/967M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  50% 482M/967M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  52% 503M/967M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  54% 524M/967M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  56% 545M/967M [00:02<00:02, 183MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  59% 566M/967M [00:02<00:02, 182MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  61% 587M/967M [00:03<00:02, 184MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  63% 608M/967M [00:03<00:01, 185MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  65% 629M/967M [00:03<00:01, 187MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  67% 650M/967M [00:03<00:01, 188MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  69% 671M/967M [00:03<00:01, 188MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  72% 692M/967M [00:03<00:01, 192MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  74% 713M/967M [00:03<00:01, 190MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  76% 734M/967M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  78% 755M/967M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  80% 776M/967M [00:04<00:00, 195MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  82% 797M/967M [00:04<00:00, 197MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  85% 818M/967M [00:04<00:00, 195MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  87% 839M/967M [00:04<00:00, 195MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  89% 860M/967M [00:04<00:00, 192MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  91% 881M/967M [00:04<00:00, 192MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  93% 902M/967M [00:04<00:00, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  95% 923M/967M [00:04<00:00, 196MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  98% 944M/967M [00:04<00:00, 196MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors: 100% 967M/967M [00:05<00:00, 192MB/s]\n",
            "Downloading shards:  93% 13/14 [01:14<00:05,  5.98s/it]\n",
            "model-00014-of-00014.safetensors:   0% 0.00/847M [00:00<?, ?B/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   2% 21.0M/847M [00:00<00:04, 200MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   5% 41.9M/847M [00:00<00:04, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   7% 62.9M/847M [00:00<00:04, 190MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  10% 83.9M/847M [00:00<00:05, 148MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  12% 105M/847M [00:00<00:04, 162MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  15% 126M/847M [00:00<00:04, 173MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  17% 147M/847M [00:00<00:03, 177MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  20% 168M/847M [00:00<00:03, 184MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  22% 189M/847M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  25% 210M/847M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  27% 231M/847M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  30% 252M/847M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  32% 273M/847M [00:01<00:02, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  35% 294M/847M [00:01<00:02, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  37% 315M/847M [00:01<00:02, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  40% 336M/847M [00:01<00:02, 189MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  42% 357M/847M [00:01<00:02, 189MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  45% 377M/847M [00:02<00:02, 189MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  47% 398M/847M [00:02<00:02, 188MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  50% 419M/847M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  52% 440M/847M [00:02<00:02, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  54% 461M/847M [00:02<00:02, 190MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  57% 482M/847M [00:02<00:01, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  59% 503M/847M [00:02<00:01, 194MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  62% 524M/847M [00:02<00:01, 197MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  64% 545M/847M [00:02<00:01, 196MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  67% 566M/847M [00:03<00:01, 196MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  69% 587M/847M [00:03<00:01, 193MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  72% 608M/847M [00:03<00:01, 193MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  74% 629M/847M [00:03<00:01, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  77% 650M/847M [00:03<00:01, 192MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  79% 671M/847M [00:03<00:00, 195MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  82% 692M/847M [00:03<00:00, 194MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  84% 713M/847M [00:03<00:00, 194MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  87% 734M/847M [00:04<00:00, 120MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  89% 755M/847M [00:04<00:00, 135MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  92% 776M/847M [00:04<00:00, 148MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  94% 797M/847M [00:04<00:00, 159MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  97% 818M/847M [00:04<00:00, 165MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors: 100% 847M/847M [00:04<00:00, 180MB/s]\n",
            "Downloading shards: 100% 14/14 [01:19<00:00,  5.65s/it]\n",
            "Loading checkpoint shards: 100% 14/14 [00:17<00:00,  1.28s/it]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 789kB/s]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-24 01:15:00\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mUsing block size 256\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-24 01:15:00\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m339\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "  0% 0/1120 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6142, 'learning_rate': 8.92857142857143e-06, 'epoch': 0.18}\n",
            "{'loss': 1.5204, 'learning_rate': 1.785714285714286e-05, 'epoch': 0.36}\n",
            "  1% 12/1120 [00:58<1:15:31,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.5283, 'learning_rate': 2.6785714285714288e-05, 'epoch': 1.11}\n",
            "{'loss': 1.4561, 'learning_rate': 3.571428571428572e-05, 'epoch': 1.29}\n",
            "  2% 24/1120 [01:55<1:14:37,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.357, 'learning_rate': 4.464285714285715e-05, 'epoch': 2.04}\n",
            "{'loss': 1.2338, 'learning_rate': 5.3571428571428575e-05, 'epoch': 2.21}\n",
            "{'loss': 1.0718, 'learning_rate': 6.25e-05, 'epoch': 2.39}\n",
            "  3% 36/1120 [02:51<1:13:48,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.94, 'learning_rate': 7.142857142857143e-05, 'epoch': 3.14}\n",
            "{'loss': 0.8301, 'learning_rate': 8.035714285714287e-05, 'epoch': 3.32}\n",
            "  4% 48/1120 [03:48<1:13:00,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.7591, 'learning_rate': 8.92857142857143e-05, 'epoch': 4.07}\n",
            "{'loss': 0.5892, 'learning_rate': 9.821428571428572e-05, 'epoch': 4.25}\n",
            "{'loss': 0.6457, 'learning_rate': 0.00010714285714285715, 'epoch': 4.43}\n",
            "  5% 60/1120 [04:45<1:12:13,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.5129, 'learning_rate': 0.00011607142857142858, 'epoch': 5.18}\n",
            "{'loss': 0.4948, 'learning_rate': 0.000125, 'epoch': 5.36}\n",
            "  6% 72/1120 [05:42<1:11:24,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.4627, 'learning_rate': 0.00013392857142857144, 'epoch': 6.11}\n",
            "{'loss': 0.3996, 'learning_rate': 0.00014285714285714287, 'epoch': 6.29}\n",
            "  8% 84/1120 [06:39<1:10:34,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.3138, 'learning_rate': 0.00015178571428571427, 'epoch': 7.04}\n",
            "{'loss': 0.2758, 'learning_rate': 0.00016071428571428573, 'epoch': 7.21}\n",
            "{'loss': 0.2587, 'learning_rate': 0.00016964285714285714, 'epoch': 7.39}\n",
            "  9% 96/1120 [07:36<1:09:46,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.211, 'learning_rate': 0.0001785714285714286, 'epoch': 8.14}\n",
            "{'loss': 0.205, 'learning_rate': 0.0001875, 'epoch': 8.32}\n",
            " 10% 108/1120 [08:33<1:08:57,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1957, 'learning_rate': 0.00019642857142857144, 'epoch': 9.07}\n",
            "{'loss': 0.1647, 'learning_rate': 0.00019940476190476191, 'epoch': 9.25}\n",
            "{'loss': 0.1585, 'learning_rate': 0.00019841269841269844, 'epoch': 9.43}\n",
            " 11% 120/1120 [09:30<1:08:07,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1217, 'learning_rate': 0.00019742063492063494, 'epoch': 10.18}\n",
            "{'loss': 0.1357, 'learning_rate': 0.00019642857142857144, 'epoch': 10.36}\n",
            " 12% 132/1120 [10:27<1:07:19,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1135, 'learning_rate': 0.00019543650793650793, 'epoch': 11.11}\n",
            "{'loss': 0.1044, 'learning_rate': 0.00019444444444444446, 'epoch': 11.29}\n",
            " 13% 144/1120 [11:24<1:06:30,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0999, 'learning_rate': 0.00019345238095238096, 'epoch': 12.04}\n",
            "{'loss': 0.0774, 'learning_rate': 0.00019246031746031748, 'epoch': 12.21}\n",
            "{'loss': 0.0909, 'learning_rate': 0.00019146825396825398, 'epoch': 12.39}\n",
            " 14% 156/1120 [12:22<1:05:41,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0697, 'learning_rate': 0.00019047619047619048, 'epoch': 13.14}\n",
            "{'loss': 0.0683, 'learning_rate': 0.00018948412698412698, 'epoch': 13.32}\n",
            " 15% 168/1120 [13:19<1:04:52,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0683, 'learning_rate': 0.0001884920634920635, 'epoch': 14.07}\n",
            "{'loss': 0.0578, 'learning_rate': 0.0001875, 'epoch': 14.25}\n",
            "{'loss': 0.0599, 'learning_rate': 0.00018650793650793653, 'epoch': 14.43}\n",
            " 16% 180/1120 [14:16<1:04:03,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0491, 'learning_rate': 0.00018551587301587303, 'epoch': 15.18}\n",
            "{'loss': 0.044, 'learning_rate': 0.00018452380952380955, 'epoch': 15.36}\n",
            " 17% 192/1120 [15:13<1:03:13,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0339, 'learning_rate': 0.00018353174603174602, 'epoch': 16.11}\n",
            "{'loss': 0.0372, 'learning_rate': 0.00018253968253968255, 'epoch': 16.29}\n",
            " 18% 204/1120 [16:10<1:02:23,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.039, 'learning_rate': 0.00018154761904761905, 'epoch': 17.04}\n",
            "{'loss': 0.0314, 'learning_rate': 0.00018055555555555557, 'epoch': 17.21}\n",
            "{'loss': 0.0362, 'learning_rate': 0.00017956349206349207, 'epoch': 17.39}\n",
            " 19% 216/1120 [17:07<1:01:34,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0276, 'learning_rate': 0.0001785714285714286, 'epoch': 18.14}\n",
            "{'loss': 0.03, 'learning_rate': 0.00017757936507936507, 'epoch': 18.32}\n",
            " 20% 228/1120 [18:04<1:00:43,  4.08s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0296, 'learning_rate': 0.0001765873015873016, 'epoch': 19.07}\n",
            "{'loss': 0.0225, 'learning_rate': 0.0001755952380952381, 'epoch': 19.25}\n",
            "{'loss': 0.0298, 'learning_rate': 0.00017460317460317462, 'epoch': 19.43}\n",
            " 21% 240/1120 [19:01<59:56,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0234, 'learning_rate': 0.00017361111111111112, 'epoch': 20.18}\n",
            "{'loss': 0.0211, 'learning_rate': 0.00017261904761904764, 'epoch': 20.36}\n",
            " 22% 252/1120 [19:58<59:08,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0201, 'learning_rate': 0.00017162698412698411, 'epoch': 21.11}\n",
            "{'loss': 0.0214, 'learning_rate': 0.00017063492063492064, 'epoch': 21.29}\n",
            " 24% 264/1120 [20:55<58:19,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0208, 'learning_rate': 0.00016964285714285714, 'epoch': 22.04}\n",
            "{'loss': 0.0159, 'learning_rate': 0.00016865079365079366, 'epoch': 22.21}\n",
            "{'loss': 0.0176, 'learning_rate': 0.00016765873015873016, 'epoch': 22.39}\n",
            " 25% 276/1120 [21:52<57:30,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0161, 'learning_rate': 0.0001666666666666667, 'epoch': 23.14}\n",
            "{'loss': 0.0159, 'learning_rate': 0.0001656746031746032, 'epoch': 23.32}\n",
            " 26% 288/1120 [22:49<56:41,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0149, 'learning_rate': 0.00016468253968253969, 'epoch': 24.07}\n",
            "{'loss': 0.0139, 'learning_rate': 0.00016369047619047618, 'epoch': 24.25}\n",
            "{'loss': 0.0154, 'learning_rate': 0.0001626984126984127, 'epoch': 24.43}\n",
            " 27% 300/1120 [23:46<55:51,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0114, 'learning_rate': 0.0001617063492063492, 'epoch': 25.18}\n",
            "{'loss': 0.0151, 'learning_rate': 0.00016071428571428573, 'epoch': 25.36}\n",
            " 28% 312/1120 [24:42<55:01,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0132, 'learning_rate': 0.00015972222222222223, 'epoch': 26.11}\n",
            "{'loss': 0.0122, 'learning_rate': 0.00015873015873015873, 'epoch': 26.29}\n",
            " 29% 324/1120 [25:39<54:10,  4.08s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0121, 'learning_rate': 0.00015773809523809523, 'epoch': 27.04}\n",
            "{'loss': 0.011, 'learning_rate': 0.00015674603174603175, 'epoch': 27.21}\n",
            "{'loss': 0.0129, 'learning_rate': 0.00015575396825396825, 'epoch': 27.39}\n",
            " 30% 336/1120 [26:36<53:23,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0111, 'learning_rate': 0.00015476190476190478, 'epoch': 28.14}\n",
            "{'loss': 0.0127, 'learning_rate': 0.00015376984126984128, 'epoch': 28.32}\n",
            " 31% 348/1120 [27:33<52:32,  4.08s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0112, 'learning_rate': 0.00015277777777777777, 'epoch': 29.07}\n",
            "{'loss': 0.0107, 'learning_rate': 0.00015178571428571427, 'epoch': 29.25}\n",
            "{'loss': 0.0117, 'learning_rate': 0.0001507936507936508, 'epoch': 29.43}\n",
            " 32% 360/1120 [28:30<51:44,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0093, 'learning_rate': 0.0001498015873015873, 'epoch': 30.18}\n",
            "{'loss': 0.0106, 'learning_rate': 0.00014880952380952382, 'epoch': 30.36}\n",
            " 33% 372/1120 [29:27<50:56,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0125, 'learning_rate': 0.00014781746031746032, 'epoch': 31.11}\n",
            "{'loss': 0.0107, 'learning_rate': 0.00014682539682539682, 'epoch': 31.29}\n",
            " 34% 384/1120 [30:24<50:06,  4.09s/it]  /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0116, 'learning_rate': 0.00014583333333333335, 'epoch': 32.04}\n",
            "{'loss': 0.009, 'learning_rate': 0.00014484126984126984, 'epoch': 32.21}\n",
            "{'loss': 0.0117, 'learning_rate': 0.00014384920634920634, 'epoch': 32.39}\n",
            " 35% 396/1120 [31:21<49:19,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0079, 'learning_rate': 0.00014285714285714287, 'epoch': 33.14}\n",
            "{'loss': 0.0105, 'learning_rate': 0.00014186507936507937, 'epoch': 33.32}\n",
            " 36% 408/1120 [32:18<48:30,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0092, 'learning_rate': 0.0001408730158730159, 'epoch': 34.07}\n",
            "{'loss': 0.0097, 'learning_rate': 0.0001398809523809524, 'epoch': 34.25}\n",
            "{'loss': 0.0098, 'learning_rate': 0.0001388888888888889, 'epoch': 34.43}\n",
            " 38% 420/1120 [33:15<47:41,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0085, 'learning_rate': 0.00013789682539682541, 'epoch': 35.18}\n",
            "{'loss': 0.0092, 'learning_rate': 0.0001369047619047619, 'epoch': 35.36}\n",
            " 39% 432/1120 [34:12<46:52,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0093, 'learning_rate': 0.00013591269841269844, 'epoch': 36.11}\n",
            "{'loss': 0.0088, 'learning_rate': 0.00013492063492063494, 'epoch': 36.29}\n",
            " 40% 444/1120 [35:09<46:03,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.009, 'learning_rate': 0.00013392857142857144, 'epoch': 37.04}\n",
            "{'loss': 0.0071, 'learning_rate': 0.00013293650793650793, 'epoch': 37.21}\n",
            "{'loss': 0.0098, 'learning_rate': 0.00013194444444444446, 'epoch': 37.39}\n",
            " 41% 456/1120 [36:06<45:14,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0074, 'learning_rate': 0.00013095238095238096, 'epoch': 38.14}\n",
            "{'loss': 0.0094, 'learning_rate': 0.00012996031746031748, 'epoch': 38.32}\n",
            " 42% 468/1120 [37:03<44:26,  4.09s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0084, 'learning_rate': 0.00012896825396825398, 'epoch': 39.07}\n",
            "{'loss': 0.0087, 'learning_rate': 0.00012797619047619048, 'epoch': 39.25}\n",
            "{'loss': 0.0089, 'learning_rate': 0.00012698412698412698, 'epoch': 39.43}\n",
            "{'train_runtime': 2281.178, 'train_samples_per_second': 3.858, 'train_steps_per_second': 0.491, 'train_loss': 0.20068517284623036, 'epoch': 39.43}\n",
            " 43% 480/1120 [38:01<50:41,  4.75s/it]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-24 01:53:02\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습결과 zip 파일로 압축후 다운로드"
      ],
      "metadata": {
        "id": "z_-YKaBW7RVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# 압축할 폴더 이름\n",
        "#folder_name = \"llama2-korquad-finetuning\"    # Data Augmentation 적용 x\n",
        "folder_name = \"llama2-korquad-finetuning-da\"  # Data Augmentation 적용 o\n",
        "\n",
        "# 생성될 ZIP 파일 이름\n",
        "#zip_file_name = \"llama2-korquad-finetuning.zip\"  # Data Augmentation 적용 x\n",
        "zip_file_name = \"llama2-korquad-finetuning-da.zip\" # Data Augmentation 적용 o\n",
        "\n",
        "# 폴더를 ZIP 파일로 압축\n",
        "shutil.make_archive(zip_file_name[:-4], 'zip', folder_name)\n",
        "\n",
        "# ZIP 파일을 로컬로 다운로드\n",
        "files.download(zip_file_name)"
      ],
      "metadata": {
        "id": "COvWT1FR7Qib",
        "outputId": "569e02ea-0485-49b4-8dfb-beee2ef1aa15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_28791862-8ade-461a-af7a-19f8db7ced7d\", \"llama2-korquad-finetuning-da.zip\", 125113064)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KkQfsjUbLRJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}