{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkwith7/aSSIST_ML/blob/main/Llama2/Llama2_fine_tuning_korquad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama 2ë¥¼ KorQuad ë°ì´í„°ì…‹ì— ë§ê²Œ fine-tuning í•˜ê¸°\n",
        "### References:\n",
        "1.   https://www.youtube.com/watch?v=LslC2nKEEGU\n",
        "2.   https://colab.research.google.com/drive/1JDnGJbxT8fSqwnXY8J-XFo73AtiSuQMe?usp=sharing"
      ],
      "metadata": {
        "id": "9oUv-sq7dqVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2sSeBHAffPi",
        "outputId": "6cc353d4-6c16-4465-fb60-6e77f791bdd2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 23 09:57:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoTrain Advanced\n",
        "https://github.com/huggingface/autotrain-advanced"
      ],
      "metadata": {
        "id": "sDwNw4-1dzJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSs7uo21QY2J",
        "outputId": "07cf4abe-9c51-4c90-f920-6979b029f8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q autotrain-advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch ì—…ë°ì´íŠ¸"
      ],
      "metadata": {
        "id": "vq_pCl2AeAkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain setup --update-torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RoZi2-uRPPE",
        "outputId": "01530145-1f63-4d0d-edd8-9dc72c9ae1bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Korquad ë°ì´í„°ì…‹ì— ë§ê²Œ Llama2 Fine-Tuning\n",
        "- í•™ìŠµ ë°ì´í„° ë””ë™í„°ë¦¬ \"korquad_prompt_da\"ë¥¼ ë§Œë“¤ê³  í•™ìŠµë°ì´í„° korquad_data_augmented.jsonë¥¼ ë””ë ‰í„°ë¦¬ì— ì—…ë¡œë“œ\n",
        "- autotrain ì„¤ì •ê°’: https://github.com/huggingface/autotrain-advanced/blob/f1367b590dfc53d240e9684779991da540590386/src/autotrain/cli/run_llm.py#L21 (**ê³¼ê±° ë²„ì „[0.6.35]**)\n",
        "- autotrain ì„¤ì •ê°’: https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/cli/run_llm.py#L17 (**ìµœì‹  ë²„ì „[0.6.80]**)\n"
      ],
      "metadata": {
        "id": "eQ2KBBcseFQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation ì ìš© x\n",
        "# !autotrain llm --train \\\n",
        "#     --project_name \"llama2-korquad-finetuning\" \\\n",
        "#     --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
        "#     --data_path \"korquad_prompt\" \\\n",
        "#     --text_column \"text\" \\\n",
        "#     --use_peft \\\n",
        "#     --use_int4 \\\n",
        "#     --learning_rate 2e-4 \\\n",
        "#     --train_batch_size 4 \\\n",
        "#     --num_train_epochs 100 \\\n",
        "#     --trainer sft \\\n",
        "#     --model_max_length 256\n",
        "# Data Augmentation ì ìš© o (ê³¼ê±° ë²„ì „)[0.6.35]\n",
        "# !autotrain llm --train \\\n",
        "#     --project_name \"llama2-korquad-finetuning-da\" \\\n",
        "#     --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
        "#     --data_path \"korquad_prompt_da\" \\\n",
        "#     --text_column \"text\" \\\n",
        "#     --use_peft \\\n",
        "#     --use_int4 \\\n",
        "#     --learning_rate 2e-4 \\\n",
        "#     --train_batch_size 8 \\\n",
        "#     --num_train_epochs 40 \\\n",
        "#     --trainer sft \\\n",
        "#     --model_max_length 256\n",
        "# Data Augmentation ì ìš© o (ìµœì‹  ë²„ì „)[0.6.80]\n",
        "!autotrain llm --train \\\n",
        "    --project-name \"llama2-korquad-finetuning-da\" \\\n",
        "    --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
        "    --data-path \"korquad_prompt_da\" \\\n",
        "    --text-column \"text\" \\\n",
        "    --peft \\\n",
        "    --quantization \"int4\" \\\n",
        "    --lr 2e-4 \\\n",
        "    --batch-size 8 \\\n",
        "    --epochs 40 \\\n",
        "    --trainer sft \\\n",
        "    --model_max_length 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8Hu-Annh0d-",
        "outputId": "30668b86-cb41-47e1-e5fb-4f9901b8a451"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=-1, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization='int4', model_max_length=256, trainer='sft', target_modules=None, merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, apply_chat_template=False, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token=None, repo_id=None, push_to_hub=False, model='TinyPixel/Llama-2-7B-bf16-sharded', project_name='llama2-korquad-finetuning-da', seed=42, epochs=40, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='korquad_prompt_da', train_split='train', valid_split=None, batch_size=8, func=<function run_llm_command_factory at 0x7eaef120d7e0>)\u001b[0m\n",
            "> \u001b[1mINFO    Starting local training...\u001b[0m\n",
            "> \u001b[1mINFO    {\"model\":\"TinyPixel/Llama-2-7B-bf16-sharded\",\"project_name\":\"llama2-korquad-finetuning-da\",\"data_path\":\"korquad_prompt_da\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":-1,\"model_max_length\":256,\"padding\":null,\"trainer\":\"sft\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0002,\"epochs\":40,\"batch_size\":8,\"warmup_ratio\":0.1,\"gradient_accumulation\":1,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.0,\"max_grad_norm\":1.0,\"seed\":42,\"apply_chat_template\":false,\"quantization\":\"int4\",\"target_modules\":null,\"merge_adapter\":false,\"peft\":true,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"prompt\",\"text_column\":\"text\",\"rejected_text_column\":\"rejected\",\"push_to_hub\":false,\"repo_id\":null,\"username\":null,\"token\":null}\u001b[0m\n",
            "> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'llama2-korquad-finetuning-da/training_params.json']\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1134.82it/s]\n",
            "Generating train split: 220 examples [00:00, 8671.78 examples/s]\n",
            "\u001b[1mğŸš€ INFO  \u001b[0m | \u001b[32m2024-01-23 10:00:24\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 220\n",
            "})\u001b[0m\n",
            "\u001b[1mğŸš€ INFO  \u001b[0m | \u001b[32m2024-01-23 10:00:24\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "tokenizer_config.json: 100% 676/676 [00:00<00:00, 3.12MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 11.3MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 19.3MB/s]\n",
            "special_tokens_map.json: 100% 411/411 [00:00<00:00, 1.98MB/s]\n",
            "config.json: 100% 626/626 [00:00<00:00, 3.11MB/s]\n",
            "model.safetensors.index.json: 100% 28.1k/28.1k [00:00<00:00, 66.3MB/s]\n",
            "Downloading shards:   0% 0/14 [00:00<?, ?it/s]\n",
            "model-00001-of-00014.safetensors:   0% 0.00/981M [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   2% 21.0M/981M [00:00<00:07, 136MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   4% 41.9M/981M [00:00<00:05, 160MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   6% 62.9M/981M [00:00<00:05, 165MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   9% 83.9M/981M [00:00<00:05, 177MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  11% 105M/981M [00:00<00:04, 187MB/s] \u001b[A\n",
            "model-00001-of-00014.safetensors:  13% 126M/981M [00:00<00:04, 193MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  15% 147M/981M [00:00<00:04, 189MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  17% 168M/981M [00:00<00:04, 184MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  19% 189M/981M [00:01<00:04, 182MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  21% 210M/981M [00:01<00:04, 185MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  25% 241M/981M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  27% 262M/981M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  29% 283M/981M [00:01<00:03, 199MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  31% 304M/981M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  33% 325M/981M [00:01<00:03, 186MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  35% 346M/981M [00:01<00:03, 185MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  37% 367M/981M [00:01<00:03, 185MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  40% 388M/981M [00:02<00:03, 185MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  42% 409M/981M [00:03<00:11, 48.8MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  44% 430M/981M [00:03<00:09, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  46% 451M/981M [00:03<00:07, 71.3MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  48% 472M/981M [00:03<00:05, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  50% 493M/981M [00:03<00:05, 89.9MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  52% 514M/981M [00:04<00:04, 104MB/s] \u001b[A\n",
            "model-00001-of-00014.safetensors:  54% 535M/981M [00:04<00:03, 122MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  57% 556M/981M [00:04<00:03, 138MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  59% 577M/981M [00:04<00:02, 136MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  61% 598M/981M [00:04<00:02, 146MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  63% 619M/981M [00:04<00:02, 159MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  65% 640M/981M [00:04<00:02, 170MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  67% 661M/981M [00:04<00:01, 180MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  69% 682M/981M [00:04<00:01, 187MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  72% 703M/981M [00:05<00:01, 192MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  74% 724M/981M [00:05<00:01, 188MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  76% 744M/981M [00:05<00:01, 186MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  78% 765M/981M [00:05<00:01, 180MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  80% 786M/981M [00:05<00:01, 178MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  82% 807M/981M [00:05<00:00, 176MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  84% 828M/981M [00:06<00:02, 74.3MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  87% 849M/981M [00:08<00:05, 24.5MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  89% 870M/981M [00:08<00:03, 33.1MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  91% 891M/981M [00:08<00:02, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  93% 912M/981M [00:08<00:01, 57.9MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  95% 933M/981M [00:09<00:00, 71.3MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  97% 954M/981M [00:09<00:00, 82.4MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors: 100% 981M/981M [00:09<00:00, 105MB/s] \n",
            "Downloading shards:   7% 1/14 [00:09<02:01,  9.38s/it]\n",
            "model-00002-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   2% 21.0M/967M [00:00<00:06, 157MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   4% 41.9M/967M [00:00<00:05, 156MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   7% 62.9M/967M [00:00<00:05, 166MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   9% 83.9M/967M [00:00<00:05, 174MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  11% 105M/967M [00:00<00:04, 184MB/s] \u001b[A\n",
            "model-00002-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 187MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 186MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 181MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  20% 189M/967M [00:01<00:04, 181MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  22% 210M/967M [00:01<00:04, 172MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  24% 231M/967M [00:01<00:04, 166MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  26% 252M/967M [00:04<00:34, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  28% 273M/967M [00:04<00:24, 28.8MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  31% 304M/967M [00:04<00:15, 43.7MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  34% 325M/967M [00:04<00:11, 55.7MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  36% 346M/967M [00:04<00:08, 70.0MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  38% 367M/967M [00:04<00:06, 86.0MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  40% 388M/967M [00:05<00:05, 100MB/s] \u001b[A\n",
            "model-00002-of-00014.safetensors:  42% 409M/967M [00:05<00:05, 111MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  44% 430M/967M [00:05<00:04, 124MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  47% 451M/967M [00:05<00:03, 134MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  49% 472M/967M [00:05<00:03, 148MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  51% 493M/967M [00:05<00:02, 160MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  53% 514M/967M [00:05<00:02, 171MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  56% 545M/967M [00:05<00:02, 185MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  59% 566M/967M [00:05<00:02, 190MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  61% 587M/967M [00:06<00:02, 185MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  63% 608M/967M [00:06<00:02, 164MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  65% 629M/967M [00:06<00:01, 171MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  67% 650M/967M [00:06<00:01, 178MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  69% 671M/967M [00:06<00:01, 185MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  72% 692M/967M [00:06<00:01, 190MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  74% 713M/967M [00:06<00:01, 191MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  76% 734M/967M [00:06<00:01, 185MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  78% 755M/967M [00:07<00:01, 181MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  80% 776M/967M [00:07<00:01, 180MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  82% 797M/967M [00:07<00:00, 177MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  85% 818M/967M [00:07<00:00, 179MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  87% 839M/967M [00:09<00:03, 35.2MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  89% 860M/967M [00:09<00:02, 46.8MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  91% 881M/967M [00:09<00:01, 60.8MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  93% 902M/967M [00:09<00:00, 71.1MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  95% 923M/967M [00:09<00:00, 81.7MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  98% 944M/967M [00:09<00:00, 98.8MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors: 100% 967M/967M [00:09<00:00, 98.0MB/s]\n",
            "Downloading shards:  14% 2/14 [00:19<01:56,  9.71s/it]\n",
            "model-00003-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   2% 21.0M/967M [00:00<00:06, 151MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   4% 41.9M/967M [00:00<00:05, 158MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   7% 62.9M/967M [00:00<00:05, 166MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   9% 83.9M/967M [00:00<00:05, 167MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  11% 105M/967M [00:00<00:05, 167MB/s] \u001b[A\n",
            "model-00003-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 174MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 177MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 185MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  20% 189M/967M [00:01<00:04, 190MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  22% 210M/967M [00:01<00:03, 192MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  24% 231M/967M [00:01<00:03, 195MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  26% 252M/967M [00:01<00:03, 187MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  28% 273M/967M [00:01<00:03, 182MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  30% 294M/967M [00:01<00:03, 179MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  33% 315M/967M [00:01<00:03, 180MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  35% 336M/967M [00:01<00:03, 181MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  37% 357M/967M [00:01<00:03, 182MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  39% 377M/967M [00:04<00:20, 29.1MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  41% 398M/967M [00:04<00:20, 27.8MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  43% 419M/967M [00:05<00:14, 37.3MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  46% 440M/967M [00:05<00:10, 49.1MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  48% 461M/967M [00:05<00:08, 62.6MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  50% 482M/967M [00:05<00:06, 75.9MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  52% 503M/967M [00:05<00:05, 87.8MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  54% 524M/967M [00:05<00:04, 103MB/s] \u001b[A\n",
            "model-00003-of-00014.safetensors:  56% 545M/967M [00:05<00:03, 120MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  59% 566M/967M [00:05<00:02, 136MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  61% 587M/967M [00:06<00:02, 151MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  63% 608M/967M [00:06<00:02, 165MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  65% 629M/967M [00:06<00:01, 176MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  67% 650M/967M [00:06<00:01, 178MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  69% 671M/967M [00:06<00:01, 179MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  72% 692M/967M [00:06<00:01, 175MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  74% 713M/967M [00:06<00:01, 173MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  76% 734M/967M [00:06<00:01, 177MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  78% 755M/967M [00:06<00:01, 180MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  81% 786M/967M [00:07<00:00, 191MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  84% 807M/967M [00:07<00:01, 126MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  87% 839M/967M [00:07<00:00, 147MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  89% 860M/967M [00:07<00:00, 159MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  91% 881M/967M [00:07<00:00, 156MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  93% 902M/967M [00:07<00:00, 161MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  95% 923M/967M [00:08<00:00, 165MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  98% 944M/967M [00:08<00:00, 170MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors: 100% 967M/967M [00:08<00:00, 117MB/s]\n",
            "Downloading shards:  21% 3/14 [00:27<01:40,  9.09s/it]\n",
            "model-00004-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   2% 21.0M/990M [00:00<00:34, 27.8MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   4% 41.9M/990M [00:00<00:16, 56.4MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   6% 62.9M/990M [00:01<00:13, 70.6MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   8% 83.9M/990M [00:01<00:10, 85.1MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  11% 105M/990M [00:01<00:08, 108MB/s]  \u001b[A\n",
            "model-00004-of-00014.safetensors:  14% 136M/990M [00:01<00:06, 137MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  16% 157M/990M [00:01<00:05, 148MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  18% 178M/990M [00:01<00:05, 147MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  20% 199M/990M [00:01<00:05, 158MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  22% 220M/990M [00:01<00:04, 167MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  24% 241M/990M [00:02<00:04, 177MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  26% 262M/990M [00:02<00:03, 184MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  29% 283M/990M [00:02<00:03, 189MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  31% 304M/990M [00:02<00:03, 184MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  33% 325M/990M [00:02<00:03, 178MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  35% 346M/990M [00:02<00:03, 179MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  37% 367M/990M [00:02<00:03, 180MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  39% 388M/990M [00:02<00:03, 177MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  41% 409M/990M [00:05<00:26, 22.3MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  43% 430M/990M [00:05<00:18, 30.4MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  46% 451M/990M [00:06<00:14, 37.7MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  48% 472M/990M [00:06<00:10, 48.4MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  50% 493M/990M [00:06<00:07, 62.7MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  52% 514M/990M [00:06<00:06, 79.1MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  54% 535M/990M [00:06<00:04, 95.6MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  56% 556M/990M [00:06<00:03, 110MB/s] \u001b[A\n",
            "model-00004-of-00014.safetensors:  58% 577M/990M [00:06<00:03, 123MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  60% 598M/990M [00:06<00:02, 140MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  62% 619M/990M [00:07<00:02, 139MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  65% 640M/990M [00:07<00:02, 148MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  67% 661M/990M [00:07<00:02, 156MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  69% 682M/990M [00:07<00:01, 158MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  71% 703M/990M [00:07<00:01, 158MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  73% 724M/990M [00:07<00:01, 162MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  75% 744M/990M [00:07<00:01, 165MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  77% 765M/990M [00:07<00:01, 164MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  79% 786M/990M [00:08<00:01, 169MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  82% 807M/990M [00:08<00:01, 174MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  84% 828M/990M [00:08<00:00, 163MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  86% 849M/990M [00:08<00:00, 151MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  88% 870M/990M [00:08<00:00, 144MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  90% 891M/990M [00:08<00:00, 136MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  92% 912M/990M [00:08<00:00, 136MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  94% 933M/990M [00:09<00:00, 137MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  96% 954M/990M [00:11<00:01, 30.0MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors: 100% 990M/990M [00:11<00:00, 87.5MB/s]\n",
            "Downloading shards:  29% 4/14 [00:39<01:40, 10.02s/it]\n",
            "model-00005-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   2% 21.0M/944M [00:00<00:05, 176MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   4% 41.9M/944M [00:00<00:05, 169MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   7% 62.9M/944M [00:00<00:05, 162MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   9% 83.9M/944M [00:00<00:05, 166MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  11% 105M/944M [00:00<00:04, 169MB/s] \u001b[A\n",
            "model-00005-of-00014.safetensors:  13% 126M/944M [00:00<00:04, 168MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  16% 147M/944M [00:00<00:04, 174MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  18% 168M/944M [00:00<00:04, 179MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  20% 189M/944M [00:01<00:04, 183MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  22% 210M/944M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  24% 231M/944M [00:01<00:03, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  27% 252M/944M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  29% 273M/944M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  31% 294M/944M [00:01<00:03, 182MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  33% 315M/944M [00:01<00:03, 177MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  36% 336M/944M [00:01<00:03, 180MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  38% 357M/944M [00:01<00:03, 179MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  40% 377M/944M [00:04<00:20, 27.1MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  42% 398M/944M [00:04<00:17, 31.4MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  44% 419M/944M [00:04<00:12, 42.1MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  47% 440M/944M [00:04<00:09, 55.2MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  49% 461M/944M [00:05<00:06, 70.5MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  51% 482M/944M [00:05<00:05, 87.8MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  53% 503M/944M [00:05<00:04, 106MB/s] \u001b[A\n",
            "model-00005-of-00014.safetensors:  56% 524M/944M [00:05<00:03, 118MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  58% 545M/944M [00:05<00:03, 126MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  60% 566M/944M [00:05<00:02, 135MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  62% 587M/944M [00:05<00:02, 145MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  64% 608M/944M [00:05<00:02, 158MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  67% 629M/944M [00:05<00:01, 168MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  69% 650M/944M [00:06<00:01, 177MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  71% 671M/944M [00:06<00:01, 185MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  73% 692M/944M [00:06<00:01, 178MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  76% 713M/944M [00:06<00:01, 182MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  78% 734M/944M [00:06<00:01, 186MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  80% 755M/944M [00:06<00:01, 187MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  82% 776M/944M [00:06<00:00, 191MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  86% 807M/944M [00:06<00:00, 193MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  88% 828M/944M [00:07<00:00, 184MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  90% 849M/944M [00:07<00:00, 180MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  92% 870M/944M [00:07<00:00, 179MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  94% 891M/944M [00:07<00:00, 181MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  97% 912M/944M [00:07<00:00, 177MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors: 100% 944M/944M [00:09<00:00, 97.8MB/s]\n",
            "Downloading shards:  36% 5/14 [00:48<01:29,  9.91s/it]\n",
            "model-00006-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   2% 21.0M/990M [00:00<00:06, 145MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   4% 41.9M/990M [00:00<00:06, 157MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   6% 62.9M/990M [00:00<00:05, 161MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   8% 83.9M/990M [00:00<00:05, 171MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  11% 105M/990M [00:00<00:05, 176MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:  13% 126M/990M [00:00<00:04, 178MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  15% 147M/990M [00:00<00:04, 178MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  17% 168M/990M [00:01<00:05, 161MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  19% 189M/990M [00:01<00:05, 155MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  21% 210M/990M [00:01<00:05, 149MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  23% 231M/990M [00:01<00:04, 152MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  25% 252M/990M [00:01<00:04, 158MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  28% 273M/990M [00:01<00:04, 158MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  30% 294M/990M [00:01<00:04, 165MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  32% 315M/990M [00:01<00:03, 170MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  34% 336M/990M [00:02<00:03, 174MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  36% 357M/990M [00:02<00:03, 176MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  38% 377M/990M [00:02<00:03, 160MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  40% 398M/990M [00:02<00:03, 165MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  42% 419M/990M [00:02<00:03, 169MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  44% 440M/990M [00:02<00:03, 174MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  47% 461M/990M [00:02<00:03, 176MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  49% 482M/990M [00:04<00:14, 34.1MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  51% 503M/990M [00:04<00:10, 45.4MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  53% 524M/990M [00:05<00:12, 38.4MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  55% 545M/990M [00:05<00:08, 50.8MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  58% 577M/990M [00:05<00:05, 72.4MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  60% 598M/990M [00:05<00:04, 85.4MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  62% 619M/990M [00:05<00:03, 100MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:  65% 640M/990M [00:06<00:03, 112MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  67% 661M/990M [00:06<00:02, 125MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  69% 682M/990M [00:06<00:02, 138MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  71% 703M/990M [00:06<00:01, 151MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  73% 724M/990M [00:06<00:01, 163MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  75% 744M/990M [00:06<00:01, 172MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  77% 765M/990M [00:06<00:01, 180MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  79% 786M/990M [00:06<00:01, 188MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  82% 807M/990M [00:07<00:01, 122MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  84% 828M/990M [00:07<00:01, 137MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  86% 849M/990M [00:07<00:00, 145MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  88% 870M/990M [00:07<00:00, 154MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  90% 891M/990M [00:07<00:00, 160MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  92% 912M/990M [00:07<00:00, 164MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  94% 933M/990M [00:07<00:00, 165MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  96% 954M/990M [00:09<00:01, 30.7MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors: 100% 990M/990M [00:10<00:00, 97.8MB/s]\n",
            "Downloading shards:  43% 6/14 [00:59<01:20, 10.00s/it]\n",
            "model-00007-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   2% 21.0M/967M [00:00<00:05, 169MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   4% 41.9M/967M [00:00<00:05, 182MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   7% 62.9M/967M [00:00<00:04, 192MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 180MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  11% 105M/967M [00:00<00:04, 176MB/s] \u001b[A\n",
            "model-00007-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 173MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 177MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 183MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  20% 189M/967M [00:01<00:04, 180MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  22% 210M/967M [00:01<00:04, 186MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  25% 241M/967M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  27% 262M/967M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  30% 294M/967M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  33% 315M/967M [00:01<00:03, 176MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  35% 336M/967M [00:01<00:03, 171MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  37% 357M/967M [00:01<00:03, 175MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  39% 377M/967M [00:02<00:03, 174MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  41% 398M/967M [00:02<00:03, 168MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  43% 419M/967M [00:04<00:19, 28.1MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  46% 440M/967M [00:05<00:19, 27.3MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  48% 461M/967M [00:05<00:13, 36.5MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  50% 482M/967M [00:05<00:10, 48.4MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  52% 503M/967M [00:05<00:07, 62.6MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  54% 524M/967M [00:05<00:05, 77.5MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  56% 545M/967M [00:05<00:04, 91.4MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  59% 566M/967M [00:05<00:03, 106MB/s] \u001b[A\n",
            "model-00007-of-00014.safetensors:  61% 587M/967M [00:06<00:03, 118MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  63% 608M/967M [00:06<00:02, 131MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  65% 629M/967M [00:06<00:02, 143MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  67% 650M/967M [00:06<00:02, 155MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  69% 671M/967M [00:06<00:01, 166MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  72% 692M/967M [00:06<00:01, 176MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  74% 713M/967M [00:06<00:01, 184MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  76% 734M/967M [00:06<00:01, 189MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  78% 755M/967M [00:06<00:01, 192MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  80% 776M/967M [00:07<00:00, 195MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  82% 797M/967M [00:07<00:00, 191MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  85% 818M/967M [00:07<00:00, 181MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  87% 839M/967M [00:07<00:00, 177MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  89% 860M/967M [00:07<00:00, 175MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  91% 881M/967M [00:07<00:00, 172MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  93% 902M/967M [00:07<00:00, 173MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  95% 923M/967M [00:07<00:00, 174MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  98% 944M/967M [00:08<00:00, 174MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors: 100% 967M/967M [00:08<00:00, 118MB/s]\n",
            "Downloading shards:  50% 7/14 [01:07<01:06,  9.44s/it]\n",
            "model-00008-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   3% 31.5M/967M [00:00<00:04, 217MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   7% 62.9M/967M [00:00<00:04, 209MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 209MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  11% 105M/967M [00:00<00:04, 209MB/s] \u001b[A\n",
            "model-00008-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 194MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 187MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 184MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  20% 189M/967M [00:00<00:04, 176MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  22% 210M/967M [00:01<00:04, 177MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  24% 231M/967M [00:01<00:04, 167MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  26% 252M/967M [00:01<00:04, 175MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  28% 273M/967M [00:01<00:04, 169MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  30% 294M/967M [00:01<00:04, 135MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  33% 315M/967M [00:01<00:04, 150MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  35% 336M/967M [00:01<00:03, 163MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  37% 357M/967M [00:02<00:03, 174MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  39% 377M/967M [00:02<00:03, 171MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  41% 398M/967M [00:02<00:03, 160MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  43% 419M/967M [00:02<00:03, 168MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  46% 440M/967M [00:02<00:02, 177MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  48% 461M/967M [00:02<00:02, 185MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  50% 482M/967M [00:02<00:02, 189MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  52% 503M/967M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  54% 524M/967M [00:02<00:02, 186MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  56% 545M/967M [00:03<00:02, 177MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  59% 566M/967M [00:03<00:03, 110MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  61% 587M/967M [00:03<00:03, 123MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  63% 608M/967M [00:03<00:02, 137MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  65% 629M/967M [00:04<00:06, 55.6MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  67% 650M/967M [00:06<00:12, 26.0MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  69% 671M/967M [00:06<00:08, 33.5MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  72% 692M/967M [00:06<00:06, 44.4MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  74% 713M/967M [00:06<00:04, 57.3MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  76% 734M/967M [00:06<00:03, 71.9MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  78% 755M/967M [00:07<00:02, 87.9MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  80% 776M/967M [00:07<00:01, 99.4MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  82% 797M/967M [00:07<00:01, 109MB/s] \u001b[A\n",
            "model-00008-of-00014.safetensors:  85% 818M/967M [00:07<00:01, 118MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  87% 839M/967M [00:07<00:01, 126MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  89% 860M/967M [00:07<00:00, 135MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  91% 881M/967M [00:07<00:00, 145MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  93% 902M/967M [00:08<00:00, 150MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  95% 923M/967M [00:08<00:00, 154MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  98% 944M/967M [00:08<00:00, 161MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors: 100% 967M/967M [00:08<00:00, 114MB/s]\n",
            "Downloading shards:  57% 8/14 [01:15<00:54,  9.16s/it]\n",
            "model-00009-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   2% 21.0M/990M [00:00<00:05, 176MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   4% 41.9M/990M [00:00<00:06, 153MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   6% 62.9M/990M [00:00<00:06, 149MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   8% 83.9M/990M [00:00<00:06, 147MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  11% 105M/990M [00:02<00:37, 23.3MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  13% 126M/990M [00:03<00:27, 31.6MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  15% 147M/990M [00:03<00:19, 43.6MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  17% 168M/990M [00:03<00:14, 58.2MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  19% 189M/990M [00:03<00:10, 75.0MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  22% 220M/990M [00:03<00:07, 101MB/s] \u001b[A\n",
            "model-00009-of-00014.safetensors:  24% 241M/990M [00:03<00:06, 115MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  26% 262M/990M [00:03<00:05, 122MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  29% 283M/990M [00:03<00:05, 134MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  31% 304M/990M [00:03<00:04, 142MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  33% 325M/990M [00:04<00:04, 150MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  35% 346M/990M [00:04<00:04, 154MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  37% 367M/990M [00:04<00:03, 162MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  39% 388M/990M [00:04<00:03, 164MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  41% 409M/990M [00:04<00:03, 174MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  43% 430M/990M [00:04<00:03, 180MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  46% 451M/990M [00:04<00:02, 183MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  48% 472M/990M [00:04<00:02, 188MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  50% 493M/990M [00:04<00:02, 189MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  52% 514M/990M [00:05<00:02, 184MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  54% 535M/990M [00:05<00:02, 178MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  56% 556M/990M [00:05<00:02, 176MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  58% 577M/990M [00:05<00:02, 180MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  60% 598M/990M [00:07<00:12, 30.3MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  62% 619M/990M [00:07<00:09, 40.6MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  65% 640M/990M [00:07<00:07, 48.5MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  67% 661M/990M [00:07<00:05, 62.3MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  69% 682M/990M [00:08<00:03, 78.8MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  71% 703M/990M [00:08<00:02, 96.2MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  73% 724M/990M [00:08<00:02, 114MB/s] \u001b[A\n",
            "model-00009-of-00014.safetensors:  75% 744M/990M [00:08<00:01, 125MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  77% 765M/990M [00:08<00:01, 138MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  79% 786M/990M [00:08<00:01, 149MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  82% 807M/990M [00:08<00:01, 161MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  84% 828M/990M [00:08<00:01, 158MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  86% 849M/990M [00:08<00:00, 164MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  88% 870M/990M [00:09<00:00, 174MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  90% 891M/990M [00:09<00:00, 178MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  92% 912M/990M [00:09<00:00, 186MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  94% 933M/990M [00:09<00:00, 184MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  96% 954M/990M [00:09<00:00, 175MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors: 100% 990M/990M [00:09<00:00, 101MB/s]\n",
            "Downloading shards:  64% 9/14 [01:25<00:46,  9.38s/it]\n",
            "model-00010-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   2% 21.0M/944M [00:00<00:06, 137MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   4% 41.9M/944M [00:00<00:05, 162MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   7% 62.9M/944M [00:00<00:04, 179MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   9% 83.9M/944M [00:00<00:04, 189MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  11% 105M/944M [00:00<00:04, 195MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  13% 126M/944M [00:00<00:04, 191MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  16% 147M/944M [00:00<00:04, 168MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  18% 168M/944M [00:00<00:04, 163MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  20% 189M/944M [00:01<00:04, 156MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  22% 210M/944M [00:01<00:04, 156MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  24% 231M/944M [00:02<00:19, 35.8MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  27% 252M/944M [00:03<00:14, 46.7MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  29% 273M/944M [00:03<00:11, 60.3MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  31% 294M/944M [00:03<00:09, 71.0MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  33% 315M/944M [00:03<00:07, 87.8MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  36% 336M/944M [00:03<00:05, 106MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  38% 357M/944M [00:03<00:04, 123MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  40% 377M/944M [00:03<00:04, 130MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  42% 398M/944M [00:03<00:03, 138MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  44% 419M/944M [00:04<00:03, 147MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  47% 440M/944M [00:04<00:03, 160MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  49% 461M/944M [00:04<00:02, 164MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  51% 482M/944M [00:04<00:02, 172MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  53% 503M/944M [00:04<00:02, 181MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  56% 524M/944M [00:04<00:02, 186MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  58% 545M/944M [00:04<00:02, 192MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  60% 566M/944M [00:04<00:01, 197MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  62% 587M/944M [00:04<00:02, 177MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  64% 608M/944M [00:05<00:01, 179MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  67% 629M/944M [00:05<00:01, 172MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  69% 650M/944M [00:05<00:01, 168MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  71% 671M/944M [00:05<00:01, 171MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  73% 692M/944M [00:05<00:01, 172MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  76% 713M/944M [00:05<00:01, 166MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  78% 734M/944M [00:05<00:01, 166MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  80% 755M/944M [00:05<00:01, 161MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  82% 776M/944M [00:06<00:01, 164MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  84% 797M/944M [00:06<00:00, 170MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  87% 818M/944M [00:06<00:00, 172MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  89% 839M/944M [00:06<00:00, 168MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  91% 860M/944M [00:06<00:00, 174MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  93% 881M/944M [00:06<00:00, 165MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  96% 902M/944M [00:06<00:00, 150MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  98% 923M/944M [00:06<00:00, 152MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors: 100% 944M/944M [00:07<00:00, 133MB/s]\n",
            "Downloading shards:  71% 10/14 [01:32<00:34,  8.69s/it]\n",
            "model-00011-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   2% 21.0M/990M [00:00<00:06, 161MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   4% 41.9M/990M [00:00<00:05, 170MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   6% 62.9M/990M [00:00<00:05, 179MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   8% 83.9M/990M [00:00<00:06, 132MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  11% 105M/990M [00:00<00:07, 112MB/s] \u001b[A\n",
            "model-00011-of-00014.safetensors:  13% 126M/990M [00:00<00:06, 127MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  15% 147M/990M [00:01<00:05, 141MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  17% 168M/990M [00:01<00:08, 101MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  19% 189M/990M [00:01<00:07, 105MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  21% 210M/990M [00:01<00:06, 116MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  23% 231M/990M [00:01<00:06, 126MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  25% 252M/990M [00:01<00:05, 138MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  28% 273M/990M [00:02<00:04, 147MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  30% 294M/990M [00:02<00:04, 154MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  32% 315M/990M [00:02<00:04, 162MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  34% 336M/990M [00:02<00:03, 171MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  36% 357M/990M [00:02<00:03, 178MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  38% 377M/990M [00:02<00:03, 184MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  40% 398M/990M [00:02<00:03, 189MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  42% 419M/990M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  44% 440M/990M [00:02<00:02, 197MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  47% 461M/990M [00:03<00:03, 168MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  49% 482M/990M [00:03<00:02, 177MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  51% 503M/990M [00:03<00:02, 182MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  54% 535M/990M [00:03<00:02, 192MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  56% 556M/990M [00:03<00:02, 196MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  58% 577M/990M [00:03<00:02, 190MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  60% 598M/990M [00:03<00:02, 185MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  62% 619M/990M [00:03<00:02, 183MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  65% 640M/990M [00:04<00:01, 183MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  67% 661M/990M [00:04<00:01, 179MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  69% 682M/990M [00:05<00:07, 39.0MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  71% 703M/990M [00:05<00:05, 51.3MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  73% 724M/990M [00:06<00:04, 60.2MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  75% 744M/990M [00:06<00:03, 72.7MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  77% 765M/990M [00:06<00:02, 87.2MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  79% 786M/990M [00:06<00:01, 103MB/s] \u001b[A\n",
            "model-00011-of-00014.safetensors:  82% 807M/990M [00:06<00:01, 109MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  84% 828M/990M [00:06<00:01, 114MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  86% 849M/990M [00:06<00:01, 119MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  88% 870M/990M [00:07<00:00, 129MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  90% 891M/990M [00:07<00:00, 133MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  92% 912M/990M [00:07<00:00, 144MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  94% 933M/990M [00:07<00:00, 151MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  96% 954M/990M [00:07<00:00, 151MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors: 100% 990M/990M [00:07<00:00, 126MB/s]\n",
            "Downloading shards:  79% 11/14 [01:40<00:25,  8.45s/it]\n",
            "model-00012-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   2% 21.0M/967M [00:00<00:05, 178MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   4% 41.9M/967M [00:00<00:05, 155MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   7% 62.9M/967M [00:00<00:05, 157MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   9% 83.9M/967M [00:00<00:05, 150MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  11% 105M/967M [00:02<00:37, 22.9MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  13% 126M/967M [00:02<00:25, 32.7MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  16% 157M/967M [00:03<00:16, 49.8MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  18% 178M/967M [00:03<00:13, 58.0MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  21% 199M/967M [00:03<00:10, 72.9MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  23% 220M/967M [00:03<00:08, 90.1MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  25% 241M/967M [00:03<00:06, 106MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  27% 262M/967M [00:03<00:06, 117MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  29% 283M/967M [00:04<00:07, 96.1MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  31% 304M/967M [00:04<00:06, 110MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  34% 325M/967M [00:04<00:05, 125MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  36% 346M/967M [00:04<00:04, 136MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  38% 367M/967M [00:04<00:03, 151MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  40% 388M/967M [00:04<00:03, 162MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  42% 409M/967M [00:04<00:03, 172MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  44% 430M/967M [00:04<00:02, 182MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  47% 451M/967M [00:04<00:02, 188MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  50% 482M/967M [00:05<00:02, 190MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  52% 503M/967M [00:05<00:02, 173MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  54% 524M/967M [00:05<00:02, 174MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  56% 545M/967M [00:05<00:02, 173MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  59% 566M/967M [00:05<00:02, 171MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  61% 587M/967M [00:07<00:13, 29.2MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  63% 608M/967M [00:07<00:09, 39.0MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  65% 629M/967M [00:08<00:07, 48.0MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  67% 650M/967M [00:08<00:05, 60.8MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  69% 671M/967M [00:08<00:03, 77.1MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  72% 692M/967M [00:08<00:02, 94.4MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  74% 713M/967M [00:08<00:02, 113MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  76% 734M/967M [00:08<00:01, 121MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  78% 755M/967M [00:08<00:01, 128MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  80% 776M/967M [00:08<00:01, 140MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  82% 797M/967M [00:09<00:01, 154MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  85% 818M/967M [00:09<00:00, 167MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  87% 839M/967M [00:09<00:00, 174MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  89% 860M/967M [00:09<00:00, 182MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  91% 881M/967M [00:09<00:00, 186MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  93% 902M/967M [00:09<00:00, 190MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  95% 923M/967M [00:09<00:00, 176MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  98% 944M/967M [00:09<00:00, 169MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors: 100% 967M/967M [00:10<00:00, 96.6MB/s]\n",
            "Downloading shards:  86% 12/14 [01:50<00:17,  8.95s/it]\n",
            "model-00013-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   3% 31.5M/967M [00:00<00:04, 214MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   7% 62.9M/967M [00:00<00:04, 207MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 208MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  12% 115M/967M [00:00<00:04, 208MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  14% 136M/967M [00:00<00:04, 196MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  16% 157M/967M [00:00<00:04, 180MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  18% 178M/967M [00:00<00:04, 178MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  21% 199M/967M [00:01<00:04, 180MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  23% 220M/967M [00:01<00:04, 179MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  25% 241M/967M [00:02<00:17, 41.5MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  27% 262M/967M [00:02<00:13, 53.5MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  29% 283M/967M [00:03<00:15, 44.7MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  33% 315M/967M [00:03<00:10, 64.6MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  35% 336M/967M [00:03<00:07, 79.3MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  37% 357M/967M [00:03<00:06, 91.4MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  39% 377M/967M [00:03<00:05, 105MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  41% 398M/967M [00:03<00:04, 123MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  43% 419M/967M [00:04<00:03, 139MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  46% 440M/967M [00:04<00:03, 154MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  48% 461M/967M [00:04<00:03, 167MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  50% 482M/967M [00:04<00:02, 167MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  52% 503M/967M [00:04<00:02, 168MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  54% 524M/967M [00:04<00:02, 171MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  56% 545M/967M [00:04<00:02, 170MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  59% 566M/967M [00:04<00:02, 171MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  61% 587M/967M [00:04<00:02, 179MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  63% 608M/967M [00:05<00:01, 183MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  65% 629M/967M [00:05<00:01, 188MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  67% 650M/967M [00:05<00:01, 192MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  69% 671M/967M [00:05<00:01, 195MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  72% 692M/967M [00:05<00:01, 190MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  74% 713M/967M [00:05<00:01, 185MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  76% 734M/967M [00:05<00:01, 183MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  78% 755M/967M [00:05<00:01, 179MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  80% 776M/967M [00:07<00:05, 32.7MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  82% 797M/967M [00:07<00:03, 43.5MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  85% 818M/967M [00:08<00:02, 52.1MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  87% 839M/967M [00:08<00:01, 65.0MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  89% 860M/967M [00:08<00:01, 81.6MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  91% 881M/967M [00:08<00:00, 99.3MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  93% 902M/967M [00:08<00:00, 114MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  95% 923M/967M [00:08<00:00, 123MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  98% 944M/967M [00:08<00:00, 134MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors: 100% 967M/967M [00:08<00:00, 108MB/s]\n",
            "Downloading shards:  93% 13/14 [01:59<00:08,  8.97s/it]\n",
            "model-00014-of-00014.safetensors:   0% 0.00/847M [00:00<?, ?B/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   2% 21.0M/847M [00:00<00:04, 186MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   5% 41.9M/847M [00:00<00:04, 197MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   7% 62.9M/847M [00:00<00:03, 200MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  10% 83.9M/847M [00:00<00:03, 203MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  14% 115M/847M [00:00<00:03, 207MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  16% 136M/847M [00:00<00:03, 185MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  19% 157M/847M [00:00<00:03, 178MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  21% 178M/847M [00:00<00:03, 175MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  24% 199M/847M [00:01<00:03, 176MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  26% 220M/847M [00:01<00:03, 179MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  28% 241M/847M [00:04<00:29, 20.2MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  31% 262M/847M [00:04<00:21, 27.4MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  33% 283M/847M [00:04<00:15, 36.9MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  36% 304M/847M [00:04<00:11, 48.3MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  38% 325M/847M [00:04<00:08, 62.0MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  41% 346M/847M [00:04<00:06, 75.6MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  43% 367M/847M [00:05<00:05, 85.4MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  46% 388M/847M [00:05<00:04, 97.0MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  48% 409M/847M [00:05<00:04, 106MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  51% 430M/847M [00:05<00:03, 117MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  53% 451M/847M [00:05<00:03, 129MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  56% 472M/847M [00:05<00:02, 138MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  58% 493M/847M [00:05<00:02, 150MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  61% 514M/847M [00:06<00:02, 158MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  63% 535M/847M [00:06<00:01, 161MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  66% 556M/847M [00:06<00:01, 162MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  68% 577M/847M [00:06<00:01, 149MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  71% 598M/847M [00:06<00:01, 146MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  73% 619M/847M [00:06<00:01, 143MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  75% 640M/847M [00:06<00:01, 144MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  78% 661M/847M [00:08<00:06, 30.4MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  80% 682M/847M [00:09<00:04, 39.0MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  83% 703M/847M [00:09<00:02, 49.0MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  85% 724M/847M [00:09<00:01, 63.5MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  88% 744M/847M [00:09<00:01, 80.0MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  90% 765M/847M [00:09<00:00, 97.6MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  93% 786M/847M [00:09<00:00, 113MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  95% 807M/847M [00:09<00:00, 126MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors: 100% 847M/847M [00:10<00:00, 84.4MB/s]\n",
            "Downloading shards: 100% 14/14 [02:09<00:00,  9.28s/it]\n",
            "Loading checkpoint shards: 100% 14/14 [01:11<00:00,  5.09s/it]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 702kB/s]\n",
            "\u001b[1mğŸš€ INFO  \u001b[0m | \u001b[32m2024-01-23 10:03:50\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mUsing block size 256\u001b[0m\n",
            "\u001b[1mğŸš€ INFO  \u001b[0m | \u001b[32m2024-01-23 10:03:50\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m339\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "  0% 0/1120 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6142, 'learning_rate': 8.92857142857143e-06, 'epoch': 0.18}\n",
            "{'loss': 1.52, 'learning_rate': 1.785714285714286e-05, 'epoch': 0.36}\n",
            "  1% 12/1120 [04:22<5:50:32, 18.98s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.5272, 'learning_rate': 2.6785714285714288e-05, 'epoch': 1.11}\n",
            "{'loss': 1.4539, 'learning_rate': 3.571428571428572e-05, 'epoch': 1.29}\n",
            "  2% 24/1120 [08:45<5:46:22, 18.96s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.3561, 'learning_rate': 4.464285714285715e-05, 'epoch': 2.04}\n",
            "{'loss': 1.2335, 'learning_rate': 5.3571428571428575e-05, 'epoch': 2.21}\n",
            "{'loss': 1.0695, 'learning_rate': 6.25e-05, 'epoch': 2.39}\n",
            "  3% 36/1120 [13:08<5:42:22, 18.95s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.9393, 'learning_rate': 7.142857142857143e-05, 'epoch': 3.14}\n",
            "{'loss': 0.8304, 'learning_rate': 8.035714285714287e-05, 'epoch': 3.32}\n",
            "  4% 48/1120 [17:32<5:38:51, 18.97s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.7579, 'learning_rate': 8.92857142857143e-05, 'epoch': 4.07}\n",
            "{'loss': 0.5882, 'learning_rate': 9.821428571428572e-05, 'epoch': 4.25}\n",
            "{'loss': 0.6451, 'learning_rate': 0.00010714285714285715, 'epoch': 4.43}\n",
            "  5% 60/1120 [21:55<5:35:13, 18.98s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.5118, 'learning_rate': 0.00011607142857142858, 'epoch': 5.18}\n",
            "{'loss': 0.4948, 'learning_rate': 0.000125, 'epoch': 5.36}\n",
            "  6% 72/1120 [26:19<5:31:24, 18.97s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.4622, 'learning_rate': 0.00013392857142857144, 'epoch': 6.11}\n",
            "{'loss': 0.3996, 'learning_rate': 0.00014285714285714287, 'epoch': 6.29}\n",
            "  8% 84/1120 [30:42<5:27:37, 18.97s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.3123, 'learning_rate': 0.00015178571428571427, 'epoch': 7.04}\n",
            "{'loss': 0.2768, 'learning_rate': 0.00016071428571428573, 'epoch': 7.21}\n",
            "{'loss': 0.2496, 'learning_rate': 0.00016964285714285714, 'epoch': 7.39}\n",
            "  9% 96/1120 [35:05<5:23:19, 18.94s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.2054, 'learning_rate': 0.0001785714285714286, 'epoch': 8.14}\n",
            "{'loss': 0.2034, 'learning_rate': 0.0001875, 'epoch': 8.32}\n",
            " 10% 108/1120 [39:29<5:20:07, 18.98s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1932, 'learning_rate': 0.00019642857142857144, 'epoch': 9.07}\n",
            "{'loss': 0.1607, 'learning_rate': 0.00019940476190476191, 'epoch': 9.25}\n",
            "{'loss': 0.1568, 'learning_rate': 0.00019841269841269844, 'epoch': 9.43}\n",
            " 11% 120/1120 [43:52<5:16:10, 18.97s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1182, 'learning_rate': 0.00019742063492063494, 'epoch': 10.18}\n",
            "{'loss': 0.1344, 'learning_rate': 0.00019642857142857144, 'epoch': 10.36}\n",
            " 12% 132/1120 [48:15<5:12:10, 18.96s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.112, 'learning_rate': 0.00019543650793650793, 'epoch': 11.11}\n",
            "{'loss': 0.1022, 'learning_rate': 0.00019444444444444446, 'epoch': 11.29}\n",
            " 13% 144/1120 [52:39<5:08:20, 18.96s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0981, 'learning_rate': 0.00019345238095238096, 'epoch': 12.04}\n",
            "{'loss': 0.0762, 'learning_rate': 0.00019246031746031748, 'epoch': 12.21}\n",
            "{'loss': 0.0949, 'learning_rate': 0.00019146825396825398, 'epoch': 12.39}\n",
            " 14% 156/1120 [57:02<5:04:46, 18.97s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0697, 'learning_rate': 0.00019047619047619048, 'epoch': 13.14}\n",
            "{'loss': 0.0666, 'learning_rate': 0.00018948412698412698, 'epoch': 13.32}\n",
            " 15% 168/1120 [1:01:25<5:01:01, 18.97s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.064, 'learning_rate': 0.0001884920634920635, 'epoch': 14.07}\n",
            "{'loss': 0.056, 'learning_rate': 0.0001875, 'epoch': 14.25}\n",
            "{'loss': 0.058, 'learning_rate': 0.00018650793650793653, 'epoch': 14.43}\n",
            " 16% 180/1120 [1:05:49<4:56:56, 18.95s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0468, 'learning_rate': 0.00018551587301587303, 'epoch': 15.18}\n",
            "{'loss': 0.0435, 'learning_rate': 0.00018452380952380955, 'epoch': 15.36}\n",
            " 17% 192/1120 [1:10:12<4:52:30, 18.91s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.036, 'learning_rate': 0.00018353174603174602, 'epoch': 16.11}\n",
            "{'loss': 0.0357, 'learning_rate': 0.00018253968253968255, 'epoch': 16.29}\n",
            " 18% 204/1120 [1:14:35<4:48:59, 18.93s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0374, 'learning_rate': 0.00018154761904761905, 'epoch': 17.04}\n",
            "{'loss': 0.0293, 'learning_rate': 0.00018055555555555557, 'epoch': 17.21}\n",
            "{'loss': 0.0332, 'learning_rate': 0.00017956349206349207, 'epoch': 17.39}\n",
            " 19% 216/1120 [1:18:58<4:45:56, 18.98s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0283, 'learning_rate': 0.0001785714285714286, 'epoch': 18.14}\n",
            "{'loss': 0.0273, 'learning_rate': 0.00017757936507936507, 'epoch': 18.32}\n",
            " 20% 228/1120 [1:23:21<4:42:18, 18.99s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0298, 'learning_rate': 0.0001765873015873016, 'epoch': 19.07}\n",
            "{'loss': 0.0246, 'learning_rate': 0.0001755952380952381, 'epoch': 19.25}\n",
            "{'loss': 0.0306, 'learning_rate': 0.00017460317460317462, 'epoch': 19.43}\n",
            " 21% 240/1120 [1:27:45<4:38:27, 18.99s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0231, 'learning_rate': 0.00017361111111111112, 'epoch': 20.18}\n",
            "{'loss': 0.0212, 'learning_rate': 0.00017261904761904764, 'epoch': 20.36}\n",
            " 22% 252/1120 [1:32:09<4:34:39, 18.99s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0208, 'learning_rate': 0.00017162698412698411, 'epoch': 21.11}\n",
            "{'loss': 0.0223, 'learning_rate': 0.00017063492063492064, 'epoch': 21.29}\n",
            " 24% 264/1120 [1:36:32<4:30:07, 18.93s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0206, 'learning_rate': 0.00016964285714285714, 'epoch': 22.04}\n",
            "{'loss': 0.0161, 'learning_rate': 0.00016865079365079366, 'epoch': 22.21}\n",
            "{'loss': 0.0187, 'learning_rate': 0.00016765873015873016, 'epoch': 22.39}\n",
            " 25% 276/1120 [1:40:55<4:26:13, 18.93s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0169, 'learning_rate': 0.0001666666666666667, 'epoch': 23.14}\n",
            "{'loss': 0.0163, 'learning_rate': 0.0001656746031746032, 'epoch': 23.32}\n",
            " 26% 288/1120 [1:45:18<4:22:37, 18.94s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0148, 'learning_rate': 0.00016468253968253969, 'epoch': 24.07}\n",
            "{'loss': 0.0144, 'learning_rate': 0.00016369047619047618, 'epoch': 24.25}\n",
            "{'loss': 0.015, 'learning_rate': 0.0001626984126984127, 'epoch': 24.43}\n",
            " 27% 300/1120 [1:49:41<4:19:07, 18.96s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.011, 'learning_rate': 0.0001617063492063492, 'epoch': 25.18}\n",
            "{'loss': 0.0161, 'learning_rate': 0.00016071428571428573, 'epoch': 25.36}\n",
            " 28% 312/1120 [1:54:04<4:15:00, 18.94s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0128, 'learning_rate': 0.00015972222222222223, 'epoch': 26.11}\n",
            "{'loss': 0.0124, 'learning_rate': 0.00015873015873015873, 'epoch': 26.29}\n",
            " 29% 324/1120 [1:58:28<4:11:33, 18.96s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.014, 'learning_rate': 0.00015773809523809523, 'epoch': 27.04}\n",
            "{'loss': 0.0106, 'learning_rate': 0.00015674603174603175, 'epoch': 27.21}\n",
            "{'loss': 0.013, 'learning_rate': 0.00015575396825396825, 'epoch': 27.39}\n",
            " 30% 336/1120 [2:02:51<4:07:26, 18.94s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.012, 'learning_rate': 0.00015476190476190478, 'epoch': 28.14}\n",
            "{'loss': 0.0132, 'learning_rate': 0.00015376984126984128, 'epoch': 28.32}\n",
            " 31% 348/1120 [2:07:14<4:03:50, 18.95s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0115, 'learning_rate': 0.00015277777777777777, 'epoch': 29.07}\n",
            "{'loss': 0.0107, 'learning_rate': 0.00015178571428571427, 'epoch': 29.25}\n",
            "{'loss': 0.0116, 'learning_rate': 0.0001507936507936508, 'epoch': 29.43}\n",
            " 32% 360/1120 [2:11:37<3:59:58, 18.95s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0098, 'learning_rate': 0.0001498015873015873, 'epoch': 30.18}\n",
            "{'loss': 0.0104, 'learning_rate': 0.00014880952380952382, 'epoch': 30.36}\n",
            " 33% 372/1120 [2:16:01<3:56:20, 18.96s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.011, 'learning_rate': 0.00014781746031746032, 'epoch': 31.11}\n",
            "{'loss': 0.0097, 'learning_rate': 0.00014682539682539682, 'epoch': 31.29}\n",
            " 34% 384/1120 [2:20:24<3:52:16, 18.94s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0109, 'learning_rate': 0.00014583333333333335, 'epoch': 32.04}\n",
            "{'loss': 0.0078, 'learning_rate': 0.00014484126984126984, 'epoch': 32.21}\n",
            "{'loss': 0.011, 'learning_rate': 0.00014384920634920634, 'epoch': 32.39}\n",
            " 35% 396/1120 [2:24:47<3:48:59, 18.98s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0071, 'learning_rate': 0.00014285714285714287, 'epoch': 33.14}\n",
            "{'loss': 0.0098, 'learning_rate': 0.00014186507936507937, 'epoch': 33.32}\n",
            " 36% 408/1120 [2:29:11<3:45:11, 18.98s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0086, 'learning_rate': 0.0001408730158730159, 'epoch': 34.07}\n",
            "{'loss': 0.0086, 'learning_rate': 0.0001398809523809524, 'epoch': 34.25}\n",
            "{'loss': 0.0099, 'learning_rate': 0.0001388888888888889, 'epoch': 34.43}\n",
            " 38% 420/1120 [2:33:34<3:41:11, 18.96s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0073, 'learning_rate': 0.00013789682539682541, 'epoch': 35.18}\n",
            "{'loss': 0.009, 'learning_rate': 0.0001369047619047619, 'epoch': 35.36}\n",
            " 39% 432/1120 [2:37:57<3:37:33, 18.97s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0091, 'learning_rate': 0.00013591269841269844, 'epoch': 36.11}\n",
            "{'loss': 0.009, 'learning_rate': 0.00013492063492063494, 'epoch': 36.29}\n",
            " 40% 444/1120 [2:42:20<3:33:26, 18.95s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0091, 'learning_rate': 0.00013392857142857144, 'epoch': 37.04}\n",
            "{'loss': 0.0074, 'learning_rate': 0.00013293650793650793, 'epoch': 37.21}\n",
            "{'loss': 0.0098, 'learning_rate': 0.00013194444444444446, 'epoch': 37.39}\n",
            " 41% 456/1120 [2:46:44<3:30:20, 19.01s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0082, 'learning_rate': 0.00013095238095238096, 'epoch': 38.14}\n",
            "{'loss': 0.0093, 'learning_rate': 0.00012996031746031748, 'epoch': 38.32}\n",
            " 42% 468/1120 [2:51:08<3:26:21, 18.99s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0086, 'learning_rate': 0.00012896825396825398, 'epoch': 39.07}\n",
            "{'loss': 0.0093, 'learning_rate': 0.00012797619047619048, 'epoch': 39.25}\n",
            "{'loss': 0.0091, 'learning_rate': 0.00012698412698412698, 'epoch': 39.43}\n",
            "{'train_runtime': 10532.4982, 'train_samples_per_second': 0.836, 'train_steps_per_second': 0.106, 'train_loss': 0.2000328358495608, 'epoch': 39.43}\n",
            " 43% 480/1120 [2:55:32<3:54:03, 21.94s/it]\n",
            "\u001b[1mğŸš€ INFO  \u001b[0m | \u001b[32m2024-01-23 12:59:23\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í•™ìŠµê²°ê³¼ zip íŒŒì¼ë¡œ ì••ì¶•í›„ ë‹¤ìš´ë¡œë“œ"
      ],
      "metadata": {
        "id": "z_-YKaBW7RVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# ì••ì¶•í•  í´ë” ì´ë¦„\n",
        "#folder_name = \"llama2-korquad-finetuning\"    # Data Augmentation ì ìš© x\n",
        "folder_name = \"llama2-korquad-finetuning-da\"  # Data Augmentation ì ìš© o\n",
        "\n",
        "# ìƒì„±ë  ZIP íŒŒì¼ ì´ë¦„\n",
        "#zip_file_name = \"llama2-korquad-finetuning.zip\"  # Data Augmentation ì ìš© x\n",
        "zip_file_name = \"llama2-korquad-finetuning-da.zip\" # Data Augmentation ì ìš© o\n",
        "\n",
        "# í´ë”ë¥¼ ZIP íŒŒì¼ë¡œ ì••ì¶•\n",
        "shutil.make_archive(zip_file_name[:-4], 'zip', folder_name)\n",
        "\n",
        "# ZIP íŒŒì¼ì„ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ\n",
        "files.download(zip_file_name)"
      ],
      "metadata": {
        "id": "COvWT1FR7Qib",
        "outputId": "70eda814-cc9a-4647-f4fb-cdd98dab9f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_06b95c8a-a9a2-4332-a405-2bc874ac3ede\", \"llama2-korquad-finetuning-da.zip\", 125110019)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KkQfsjUbLRJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}