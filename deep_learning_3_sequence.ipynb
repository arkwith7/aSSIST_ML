{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkwith7/aSSIST_ML/blob/main/deep_learning_3_sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence to Sequence"
      ],
      "metadata": {
        "id": "oetAYDmRWWBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본적인 사용법\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        ")"
      ],
      "metadata": {
        "id": "7G5Lq2F6Oq0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 커스터마이징 하기\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "    lowercase_string = tf.strings.lower(string_tensor)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "    return tf.strings.split(string_tensor)\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn, # 정규화 과정 \n",
        "    split=custom_split_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "k4_rhhNyVYxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)"
      ],
      "metadata": {
        "id": "fFw3K6MnNxVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "어휘 사전 출력하기"
      ],
      "metadata": {
        "id": "5X2jj0sNOzoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4DmQF7DNzIu",
        "outputId": "03c9f9e5-3ff3-4242-ed30-b4f6b0fff2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'erase',\n",
              " 'write',\n",
              " 'then',\n",
              " 'rewrite',\n",
              " 'poppy',\n",
              " 'i',\n",
              " 'blooms',\n",
              " 'and',\n",
              " 'again',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08ZgdunRN0y-",
        "outputId": "d00f1362-90c7-4dc1-9b07-ddcd10ff9e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverse_vocab = dict(enumerate(vocabulary))\n",
        "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
        "print(decoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg8JPjgJN3_1",
        "outputId": "c7d33ac5-fc91-4be0-b42c-518de3c334b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 사용법 (커스터마이징 하지 않고 사용하기)\n",
        "# 기본적인 사용법\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        ")\n",
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)\n",
        "text_vectorization.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hofaa6x_tqr",
        "outputId": "1429ba4d-8109-4e11-f05f-c537b6103fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'erase',\n",
              " 'write',\n",
              " 'then',\n",
              " 'rewrite',\n",
              " 'poppy',\n",
              " 'i',\n",
              " 'blooms',\n",
              " 'and',\n",
              " 'again',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwk46O1g_9LQ",
        "outputId": "3953ed5c-f14d-47d1-e2b4-4910acaac0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단어 그룹을 표현하는 두 가지 방법: 집합과 시퀀스"
      ],
      "metadata": {
        "id": "cFI11GNsO5ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMDB 영화 리뷰 데이터 준비하기"
      ],
      "metadata": {
        "id": "sk973GwkO79e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVRyJbshO6R7",
        "outputId": "4988b759-fe91-44d2-ee69-f64a96a364a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  32.1M      0  0:00:02  0:00:02 --:--:-- 32.1M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "eEH-BjUUO-dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 폴더: 학습용 데이터. 25,000개의 데이터  \n",
        "test 폴더: 테스트용 데이터. 25,000개의 데이터  \n",
        "pos 폴더: 긍정  \n",
        "neg 폴더: 부정  "
      ],
      "metadata": {
        "id": "ByH9m2HLAv_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIjv5VJJPHD6",
        "outputId": "e2b3169e-5dd2-48f8-e515-664cb8f79183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4Er_zRoBzs5",
        "outputId": "e24593e1-f252-4b9f-e680-9e6ddaa65ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neg  pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    try:\n",
        "      os.makedirs(val_dir / category)\n",
        "    except:\n",
        "      pass\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)        # 훈련을 여러번 실행해도 동일한 검증세트가 만들어지도록 랜덤값을 고정\n",
        "    num_val_samples = int(0.2 * len(files))   # 20% 는 검증 세트로 사용함\n",
        "    val_files = files[-num_val_samples:]      # 검증 세트 분리\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ],
      "metadata": {
        "id": "csyFcLV8PHTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tTnhkCNPI7P",
        "outputId": "fb9c7657-fec2-4f83-897b-3e5b71728b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcNDI6p-En7h",
        "outputId": "aa7757da-5009-4113-8494-6398b3c12b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 첫 번째 배치의 크기와 dtype 출력하기"
      ],
      "metadata": {
        "id": "q_smLcJUPPCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMMwdZKCPLmm",
        "outputId": "c342d891-d5ae-4668-aff0-18a213837c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"Star Trek: Hidden Frontier is a long-running internet only fan film, done completely for the love of the series, and a must watch for fans of Trek. The production quality is extremely high for a fan film, although sometimes you can tell that they're green-screenin' it. This doesn't take away from the overall experience however. The CGI ships are fantastic, as well as the space battle scenes... On the negative side, I could tell in the earlier episodes (and even occasionally in the newer ones) that some of the actors/actresses are not quite comfortable in their roles, but once again, this doesn't take away from the overall experience of new interpretations of Star Trek. The cast and crew have truly come up with something special here, and, as a whole,I would highly recommend this series to fans of The Next Generation and Deep Space 9.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단어를 집합으로 처리하기: BoW 방식"
      ],
      "metadata": {
        "id": "Ccf0Zd2iPU-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single words (unigrams) with binary encoding"
      ],
      "metadata": {
        "id": "-fdVn1IiPXk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TextVectorization 층으로 데이터 전처리하기"
      ],
      "metadata": {
        "id": "jATR_FCpPYn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,   # 가장 많이 등장하는 2만개 단어로 어휘 사전 제한 -> 한두번만 등장하는 수만개의 단어는 유용하지 않음\n",
        "    output_mode=\"multi_hot\",  # 멀티-핫 이진 벡터로 출력 토큰을 인코딩\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x) # 레이블 없이 원시 텍스트 입력만 반환하는 데이터셋\n",
        "text_vectorization.adapt(text_only_train_ds)\n"
      ],
      "metadata": {
        "id": "jeZ1QuO4PRCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs in train_ds:\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(len(inputs[0]))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGhZ_aq6F5mO",
        "outputId": "b53f05b5-97f9-4568-afbf-a1ebc07d3df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[0]: tf.Tensor(\n",
            "[b'- When the local sheriff is killed, his wife takes over until and is determined to clean-up the town. Not everyone in town, however, is happy with what she\\'s doing. When the sheriff orders a curfew in town, the local saloon owner (also a woman) hires a killer to take care of the sheriff. There\\'s no way the saloon owner could know that the sheriff and the killer would fall in love.<br /><br />- Gunslinger is an example of what happens when you have a fairly interesting concept and combine it with poor execution. There\\'s a good movie here somewhere trying to get out. In more capable hands or with a larger budget, Gunslinger might have been an entertaining look at the role of women in the Old West. As it is, Gunslinger is a sloppy mess of a movie.<br /><br />- There are just so many things wrong with the movie: a supporting cast with no acting ability, stilted and unnatural dialogue, and sets that look like sets. But the biggest offender is the editing. I was amazed at how many times a scene would begin with the actors (and horses for that matter) obviously waiting for Corman to yell \"Action\". The best is the scene of two riders on horseback just standing beside a building. All of a sudden, they take off and come racing around the corner like they had been riding hard for several miles. Or, take the example of people who can seemingly transport themselves across town. We see a man enter a building and a second later emerge across town to mount his horse.<br /><br />- It\\'s not as if Corman didn\\'t have a few decent actors to work with. While none were great stars, Beverly Garland, John Ireland, and Allison Hayes were all capable of turning in a good performance. But, in Gunslinger, they\\'re not given much to work with.<br /><br />- I have now seen both the MST3K and non-MST3K versions of the movie. I would strongly recommend going the MST3K route.'\n",
            " b\"I can't believe that this movie even made it to video, and that video rental stores are willing to put it on their shelves. I literary asked for a refund. Take away the fact that the movie has no historical truth it, and it is still the worse movie ever found in a video store. It is not even good enough to be called a B rated movie. Do not waste your money or your time on this movie. Just listing to the voice over and the horrible music made me sick. Anyone involved with this movie should be pulled from the union, gives the industry a black mark, but after watching most of this movie I really don't think anyone involved is a union member.\"\n",
            " b\"Unashamedly ambitious sci-fi from Kerry Conran, for whom this is clearly a labour of love. Unfortunately it's just not that good. It all starts well enough - with an epic but restrained score, a mixture of Lucas and Hitchcock style editing and the glossy cinematography of a Spielberg. The movie also references many pulp sci-fi novels, serials and films as diverse as The Day The Earth Stood Still, Superman, Metropolis, Planet Of The Apes, The Iron Giant, Star Wars and The Spy Who Loved Me. The film however, fails to be as good as any one of those for several reasons: the main being that it's such a labour of love, so concerned with throwing everything at the screen and creating a brave new world, Conran actually forgets about making a movie. There is little to no tension, atmosphere or magic on offer here despite aerial battles, dinosaurs and race-against-time set-pieces. Even the noir elements fall flat. This is a broad way of looking at things though - those elements mainly fail because nothing feels at all real and is so obviously fake - the green-screen just looks like a video game half the time and it's obvious the actors have been pasted on afterwards. The actors don't get to do much either - Jude Law is wooden, Gwyneth Paltrow is annoying and stupid, Angelina Jolie is wasted - and it's all because of an awful script - the sort that has to explain nearly everything. It is a decent experience and some might get a nostalgia feel but ultimately this is a pointless step into the world of yesterday. Nice ending though.\"\n",
            " b\"Magnolia presents itself as a wall to wall canvas of screaming, shrieking, overwrought, hysterical twits who are all bedeviled by regret, guilt and pain. PT Anderson is certainly a gifted filmmaker but perhaps he should leave the writing to someone else or at least find someone with the balls to tell him he needed to edit this overlong mess.<br /><br />A look at the cast will tell you that the performances were excellent, and they were. I just wish that every scene didn't involve an over the top shouting match or long digression into the sins that have been committed and the pain that they have caused.<br /><br />I also think that Anderson fails miserably to create a story that parallels the bizarre tableaus that open the film. The opening sequences are wonderful in showing how fate can bring together people and circumstances that even the most optimistic believer in a cosmic puppeteer pulling our strings would scoff at. But the story that then develops lacks any of the stuff that these opening fables display. I kept waiting for some form of cosmic convergence to display itself, but instead all we get is waves of regret from morally challenged characters who see their past spread out before them and now seek absolution. Throw in an out of left field biblical plague near the end and all you end up with is a cadre of Anderson devotees who will marvel at his genius when all it really proves is that he has actually read the Old Testament.<br /><br />I will say that the music by Aimee Mann was great and I'll be looking for the Soundtrack CD. In short, a good movie to look at and listen to (the music, that is) if the actors would have shut up or toned it down it may have been\"\n",
            " b'Jack Black\\'s character, Tim Dingman the \"Dreamer\" in Envy, finds wealth and success in the idea of a aerosol spray \"Vapoorize\" that when sprayed on doggie dung, makes the poo disappear into thin air. <br /><br />For a moment I was hoping that Vapoorize was a real product so that I could spray it on this \"stinker\" of a movie and make it disappear into thin air as well.<br /><br />Although Envy is not the worst movie that I have seen in the past 12 months (that honor goes to The Cat in the Hat), it does get the honor of a close second.<br /><br />Not funny, not sad, not anything. A real \"Stinkeroo\"!!!!!<br /><br />A 0.2 out of 10!!'\n",
            " b'My wife and I have watched this whole series at least three times. I can\\'t imagine how it could be better. This isn\\'t the \"complete\" history of WWII\\xc2\\x97no library could hold such a history\\xc2\\x97but it is the best summary of that history. Lots of detail, lots of personal stories, and still keeps the overall picture in view.<br /><br />Olivier\\'s narration is excellently written and, of course, superbly given. The interviews are from all sides, except the Russian, because the producers were not allowed to talk to many Russians. It is very much worth owning this complete program on DVD. We treasure our copy.<br /><br />The producer\\'s do an excellent job of providing pictures and action where there was almost none extant in any archive: There are almost no films of convoys and submarine battles, for instance, but still, the episode on this subject is very well done.'\n",
            " b\"There wasn't a day in 2002 where i wasn't chased by a scarecrow I felt that this film handled a serious issue well<br /><br />It brought back a lot of memories as it was so realistic<br /><br />Even today I have nightmares about corn on the cob, and can't even go near the tinned stuff in fear of my life<br /><br />I have to admit though, at one point in the film I did have to turn it off as it hit too close to home<br /><br />For those of you who have never been attacked by a scarecrow, by watching this film you could be educated about how it felt for us victims <br /><br />This film teaches us not to take life for granted or to mess with corn, believe me, I've been there and I have the scars <br /><br />Watch the film, its amazing and educational\"\n",
            " b\"Murder in Mesopotamia, I have always considered one of the better Poirot books, as it is very creepy and has an ingenious ending. There is no doubt that the TV adaptation is visually striking, with some lovely photography and a very haunting music score. As always David Suchet is impeccable as Hercule Poirot, the comedic highlight of the episode being Poirot's battle with a mosquito in the middle of the night, and Hugh Fraser is good as the rather naive Captain Hastings. The remainder of the cast turn in decent performances, but are careful not to overshadow the two leads, a danger in some Christie adaptations. Some of the episode was quite creepy, a juxtaposition of an episode as tragic as Five Little Pigs, an episode that I enjoyed a lot more than this one. What made it creepy in particular, putting aside the music was when Louise Leidner sees the ghostly face through the window. About the adaptation, it was fairly faithful to the book, but I will say that there were three things I didn't like. The main problem was the pacing, it is rather slow, and there are some scenes where very little happens. I didn't like the fact also that they made Joseph Mercado a murderer. In the book, I see him as a rather nervous character, but the intervention of the idea of making him a murderer, and under-developing that, made him a less appealing character, though I am glad they didn't miss his drug addiction. (I also noticed that the writers left out the fact that Mrs Mercado in the book falls into hysteria when she believes she is the murderer's next victim.) The other thing that wasn't so impressive was that I felt that it may have been more effective if the adaptation had been in the viewpoint of Amy Leatheran, like it was in the book, Amy somehow seemed less sensitive in the adaptation. On the whole, despite some misjudgements on the writers' behalf, I liked Murder in Mesopotamia. 7/10 Bethany Cox.\"\n",
            " b\"I'd waited for some years before this movie finally got released in England, but was in many ways very pleased when I finally saw it. There are a lot of great things to the film, for a start the acting. Its not something I have all that much need for in a horror picture but the people in this film all put in fine work. This and the constantly gripping and interesting script, with a nice sorta Lovecraftian feel to it, give the film a real solid backbone. Add to this the doses of surreal nightmare imagery and occasional gruesome gore and the films a winner. It has my favorite kind of gore too, supernatural and splattery. Also, the characters of Marcus, the angry bodybuilding transsexual and Daisy, his mentally retarded lover/plaything are genuinely freakish and unnerving at times, and give a far out, anything goes sense of morbid grown up craziness which works well with the frequent Freudian overtones. This is one of the most impressive recent horror movies, far more shocking or out there than anything Hollywood can produce. My only gripe was that I wanted the ending to be darker in tone, but it still works, so on the whole I'd really recommend this to serious horror buffs.\"\n",
            " b'I first saw this film 40 years ago on N.Y. television, and thought it was a depressing look at the future. Wells sees restriction of private freedoms as a good thing. (\" no private airplanes\". The 30 year plus war in the film was the reason this film was not shown to British film goers doing the war. The concept of the future, and the Korda an Co. concept of the the machines of the future are the real stars of the film. The very best acting performance is that of Ralph Richardson as the Boss. A combination of Winston Churchill and Edina from Absolutely Fabulous comedy series. It is interesting to note that the Boss\\'s negative personality is somewhat similar to the war time Churchill.'\n",
            " b\"Robert A. Heinlein's classic novel Starship Troopers has been messed around with in recent years, in everything to Paul Verhoeven's 1997 film to a TV series, to a number of games. But none of these, so to speak, has really captured the spirit of his novel. The games are usually unrelated, the TV series was more of a spin off, and the less said about Verhoeven's film, the better. Little do most know, however, that in Japan, an animated adaptation had already been done, released the year of Heinlein's death. And, believe it or not, despite its differences, this 6-part animated series is, plot-wise, the most faithful adaptation of Heinlein's classic.<br /><br />The most obvious plus to this series is the presence of the powered armor exoskeletons, something we were deprived of in Verhoeven's film. Like the book, the series focuses more on the characters and their relationships than on action and space travel, though we see a fair amount of each. While events happen differently than in the book, the feel of the book's plot is present. Rico and Carmen have a romantic entanglement, but it's only slightly more touched upon than in the book. While some may believe the dialogue and character interaction to be a bit inferior to the book (it gets a bit of the anime treatment, but what did you expect?), but it's far superior to the film. Heinlein's political views are merely excised, as opposed to the film, where they are reversed. The big payoff of the series, however, is the climatic battle on Klendathu between the troopers and the bugs/aliens, which features the kind of action from the powered armor suits we would have like to have seen in a film version.<br /><br />Overall, I enjoyed this series because I wanted to see a vision closer to that of Heinlein. And I think they did pretty well with this. If you can find this series, give it a look.\"\n",
            " b\"I really liked this movie. I've read a few of the other comments, and although I pity those who did not understand it, I do agree with some of the criticisms. Which, in a strange way, makes me like this movie all the more. I accept that they have got a pretty cast to remake an intelligent movie for the general public, yet it has so many levels and is still great to watch. I also love the movies, such as this one, which provoke so many debates, theories, possible endings and hidden subtext. Congratulations Mr.Crowe, definitely in my Top Ten.<br /><br />P.S. Saw this when it first came out whilst I was backpacking in Mexico, it was late at night and I had to get back to my hotel and I had a major paranoia trip! Where does the dream end and the real begin?\"\n",
            " b'\"Jared Diamond made a point in the first episode that other peoples of the world didn\\'t have animals to domesticate but Europeans did, and that accounts for why we were able to make steel and invent complex machines\". --- It is obvious that the person who wrote this comment hasn\\'t understood the reasoning behind this documentary or the original book. Please don\\'t ruin this great piece by your simple mindedness. The reasons are far more complex than the single thing you mentioned. Please read the book as is it a great source of information. I enjoyed it a lot. This book is even a taught as a text book at some universities.'\n",
            " b'A film that dramatized an understandable reluctance to face the inevitable coming of the the second world war, when a Spanish Republican, sent by his soon to be overthrown government, (Charles Boyer) infiltrates himself into England looking for support for his cause by trying to influence wealthy mine owners not to sell coal to the fascists back in Spain. He upsets the locals, getting convincingly beaten in one scene, and later in the film facing an angry crowd of miners who see him as yet another threat to their shaky livelihood. Notwithstanding socio-economic hierarchy, xenophobia, and world politics, this film expertly delves into a dark and suspenseful intrigue involving unfaithful compatriots played by Katina Paxinou and Peter Lorre, and is expertly filmed in numerous darkly lit scenes set in a dreary hotel by James Wong Howe, and manages more than once to get under your skin.'\n",
            " b'Stack should have received the Academy Award for this performance, period. Its a crime that he did not. Amazing how he humanizes a rich worthless character. <br /><br />Dorothy Malone did earn a well-deserved Academy Award for her performance. In fact, all of the acting in this film is excellent.<br /><br />The plot begins with a taxi ride, then an airplane ride, then keeps moving on an emotional ride that will hold your interest throughout. You will be entertained!<br /><br />However, this is only a blatant soap opera. One-dimensional, 100-percent soaper. You might call it the ultimate soaper, because the acting so thoroughly triumphs over the material. Excellently acted, well directed, but strictly within its soap genre. I wouldn\\'t even call it a melodrama (such as \"Mildred Pierce\" or \"Imitation of Life\"). While not denying the great entertainment value of this film, you can only imagine what this talented cast and director might have achieved with more substantial subject matter.'\n",
            " b'Ok I will sum up this movie... A bunch of skanky British women have some disease that basically is turning them into zombies. The whole movie consists of these women talking, smoking, and rarely going out for \"meat\" Or humans to eat. I swear I had to MAKE myself watch this movie... UGH'\n",
            " b\"A Damsel in Distress is a delight because of the great Gershwin songs, Fred Astaire, Joan Fontaine, and a terrific supporting cast headed by Gracie Allen and George Burns.<br /><br />Typically silly plot for an Astaire film has him as an American dance star in England with Burns as his publicist and Allen his secretary. They concoct a story about his being a love bug with women falling victim to him left and right. He runs into Fontaine who is being held captive in her castle by a domineering aunt and docile father. Silly plot.<br /><br />The great songs include A Foggy Day, Things Are Looking Up, Nice Work if You Can get It, and I Can't Be Bothered Now. Fontaine does not sing, but does a brief (and decent) number with Astaire. Surprisingly good in a few dance numbers with Astaire are Burns and Allen, including an inventive and fun romp through an amusement park.<br /><br />Also in the cast are Reginald Gardiner, Constance Collier, Montagu Love, Harry Watson (as Albert), Ray Noble, and my favorite--Jan Duggan as the lead madrigal singer.<br /><br />Jan Duggan is in the middle of the swoony trio who sings Nice Work if You Can Get It. Her facial expressions are hilarious. She was also a scene stealer in the W.C. Fields comedy, The Old Fashioned Way, playing Cleopatra Pepperday.<br /><br />Much abuse has been heaped on this film because of the absence of Ginger Rogers, who, as noted elsewhere, would have been hideously miscast. The TCM host notes that Ruby Keeler and Jessie Matthews were considered. Yikes. Two more would-be disasters. Fontaine is fine as Alyce and the dynamic allows the musical numbers to belong to Astaire, with ample comic relief by Burns and Allen.<br /><br />Fun film, great songs, good cast, and Jan Duggan in a rare spotlight!\"\n",
            " b\"Maybe the greatest film ever about jazz.<br /><br />It IS jazz.<br /><br />The opening shot continues to haunt my reverie.<br /><br />Lester, of course, is wonderful and out of this world.<br /><br />Jo Jones is always a delight (see The Sound of Jazz as well).<br /><br />If you can, find the music; it's available on CD.<br /><br />All lovers of jazz and film noir should study this tremendous jewel.<br /><br />What shadows and light - what music - what a hat!\"\n",
            " b'This is one of the best Fred Astaire-Ginger Rogers films, or at least one of my favorites. Most of the A-R movies feature great dancing but sappy romance stories. This still has the courtship corniness but not as pronounced as the other films.<br /><br />This movie features not just great dancing but likable characters and a bunch of good songs. The music is the central theme here and what\\'s nice is the addition of a tap solo by Rogers. She not only was a super dancer but a very pretty woman and one with tremendous figure. She dances also with Fred, of course, and they\\'re always a fun pair to watch on the dance floor.<br /><br />Growing up in the 1950s watching \"Ozzie & Harriet\" on television, it was a real kick the first time I saw this to see such a young Harriet Hilliard. No surprise than Ozzie fell for this beauty. Although she had that short early \\'30s hairstyle, I recognized her voice right away. Also in this movie are quick appearances by Betty Grable and Lucille Ball, but I have to admit that I have yet to out Ball. I can\\'t find her, but I know she\\'s in here.<br /><br />Astaire, except for some obnoxious gum-chewing in the first third of the film, was fun to watch and Randolph Scott - although better in westerns - is likable, too.<br /><br />This is simply a nice, feel-good film and good one if you want to to enjoy the great talents of Astaire and Rogers.'\n",
            " b\"A big surprise, probably because I was expecting it to suck. The reviews were pretty dismissive of it, even though they all seemed to agree that the concept was golden: a man finds out his new girlfriend is a super hero, and finds, when he wants to break up with her, that she's kind of a psycho. I kept expecting it to fall apart, but it never really did. Sure, it doesn't make as much of its awesome premise as it could, and chooses to be short when it might have been better to expand the film's universe. But I can't blame it for that. Uma Thurman is great as the bipolar superhero, G-Girl. And I've discovered, after several years of disliking him, that Luke Wilson can be absolutely perfect when cast as a schlub. He's given two of the best comic performances of 2006 (the other in the pretty much unreleased Idiocracy). I absolutely cracked up at the expressions on his face when he and Thurman first have sex. It's one of the funniest sex scenes ever. My only real complaint is that they make G-Girl a bit too much of a psycho, like almost unbelievably so. Maybe with some background I could have accepted it better. I can forgive its flaws, though, because I had a really good time watching it. Underrated, for sure.\"\n",
            " b\"The premise is amazing and the some of the acting, notably Sally Kellerman and Anthony Rapp, is charming... but this film is near unwatchable. The music sounds as if it comes from some sort of the royalty free online site and the lyrics as if they were written with a rhyming dictionary open on the lap. Most of the singing is off-key. I think they may have filmed with the singing accapella and put in the music under it... The dialogue is really stupid and trite. The movie works best when it is actually talking about the real estate but unfortunately it strays to often into stupid farcical sub-plots. I found myself checking my watch after ther first twenty minutes and after 40 wondering 'when is it ever going to end.'\"\n",
            " b\"The monster from Enemy Mine somehow made his way into a small mountain community, where he has taken up residence. He's being hunted by a female doctor-turned-vigilante who is out to exterminate him. This female assassin, who looks like a refugee from a Motley Crue video, rides around on a motorcycle and tries to save a bunch of kids who have chosen to have a Big Chill weekend right smack dab in the middle of the monster's turf. Decapitations and lots of blood are primarily in place to draw attention away from the story which limps along like a bad version of the Island of Dr. Moreau (and yes, it's worse than the one with Val Kilmer).\"\n",
            " b\"The information contained in this movie is somewhat familiar to many who have been paying attention to the news lately. The Walter Reed scandals show a small part of the fact that we are not doing a good job taking care of our injured heroes when they return.<br /><br />What this movie further shows is a truth common to all wars. The psychological trauma that soldiers suffer while engaging in war and the difficulty they have when returning to civilian life. They are not just changed or affected, they are different people and most do not know how to deal with that as they do not know themselves.<br /><br />Finally, this film shows what the military does to our young men in women in getting them ready for war and the policies and practices that they have to follow in prosecuting war that leads to all the psychological trauma.<br /><br />We have over 3000 dead soldiers in the four years of this invasion; but we have many tens of thousands that will suffer lifelong physical and psychological trauma because of this war. It doesn't matter what side you are on, it behooves you to know the cost of war to decide if we should be in that business. This film illustrates the costs to the men and women perfectly.\"\n",
            " b\"If you've ever seen an eighties slasher, there isn't much reason to see this one. Originality often isn't one of slasher cinema's strongpoints, and it's something that this film is seriously lacking in. There really isn't much that can said about Pranks, so I'll make this quick. The film was one of the 74 films included on the DPP Video Nasty list, and that was my only reason for seeing it. The plot follows a bunch of kids that stay behind in a dorm at Christmas time. As they're in a slasher, someone decides to start picking them off and this leads to one of the dullest mysteries ever seen in a slasher movie. The fact that this movie was on the Video Nasty list is bizarre because, despite a few gory scenes, this film is hardly going to corrupt or deprave anyone, and gorier slashers than this (Friday the 13th, for example) didn't end up banned. But then again, there's banned films that are much less gory than this one (The Witch Who Came from the Sea, for example). Anyway, the conclusion of the movie is the best thing about it, as although the audience really couldn't care less who the assailant is by this point; it is rather well done. On the whole, this is a dreary and dismal slasher that even slasher fans will do well to miss.\"\n",
            " b'This is the Columbo that got directed by Steven Spielberg at an early point in his career. It\\'s nothing sensational but some small hint of great things to come for Spielberg can be seen in this movie. The movie is basically in the same style as most of Spierlberg\\'s \\'70\\'s movies and TV works. So that means that some characters tend to show some quirkiness\\'s and no I\\'m not just talking about the Columbo character alone. The kind of character quirkiness which perhaps can be best seen in the 1975 Spielberg movie \"Jaws\". But other than some small hints of typical early Spielberg elements, you can\\'t call this movie the work of- and fine example of a rising director star. Not that its bad, of course it isn\\'t but as I said earlier, it also isn\\'t anything too sensational.<br /><br />This movie began really well and very promising but after it\\'s fine opening, in which as always the murder occurred, the movie became sort of more slow and also dull to watch. Dull because it\\'s mostly a Columbo movie by the book that doesn\\'t have real memorable moments in it, not dull because it\\'s a boring movie to watch.<br /><br />The murder itself was quite ingenious and the concept of having a crime story writer murdering his writing partner showed some great and interesting potential. The story however didn\\'t really explored all of its possibilities. At least that\\'s the feeling this movie left me with.<br /><br />The movie was still a good one to watch nevertheless thanks to the character of Jack Cassidy, who thinks he\\'s smarter then Columbo, due to his mystery/crime writing experience and tries to give him all kinds of possible hints, leading away from himself. But of course Columbo knows better and he is his number one suspect from the first moment on but he as usual plays the game along.<br /><br />The movie does have a good overall style and uses some fine camera position and editing. Funny to see that also most of this was all mostly consistent with Spielberg\\'s later work, especially some of the camera-angles.<br /><br />A fine and perfectly watchable Columbo movie but don\\'t let the name of Spielberg attached to it rise your expectations for it too highly.<br /><br />7/10'\n",
            " b\"an very good storyline, good thrill to it ... but the 10 last seconds destroyed the whole movie... what happened? extremely well made and an good story destroyed in the last seconds... sorry to say but a 1 in vote... thats what it it deserve, i would think that Chris Shadley could come up with a better end... but maybe next time : ) all this meaningless blood gore for nothing? the end would lift the story to close to a 10, but it didn't.... the end destroyed the whole story, i think most people aren't lame and when they goes a movie thy want a good end, even if it is intricate ... but the only lame here is the end... sorry\"\n",
            " b'Prominent attorney Walter Pidgeon takes a murder case pro bono, wins an acquittal and discovers that his client (Keefe Braselle) was not only guilty but part of an extortion ring reaching to the highest eschelons of the city. Panged by his own complicity, he undertakes an investigation, stumbles onto the identity of the \"unknown man\" who heads the syndicate, and murders him.<br /><br />The ironies engage when Braselle is charged with this second murder and Pidgeon must defend him by pointing to the existence of another \"unknown man\" -- himself. Though somewhat short of urban grit and long on rhetoric, the Unknown Man belongs to the noir cycle less by style or structure than by its acknowledgement of the pervasive corruption of American municipal politics that came to light in the postwar years.'\n",
            " b'This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).'\n",
            " b\"I was really surprised with this movie. Going in to the sneak preview, knowing nothing about the movie except for the one trailer I'd seen, I thought it was going to be a Dude Where's My Car kind of crap fest. I was expecting bad sex jokes and farting and a pathetic lead character who will get laid in the end because that's just how movies work. Instead I got a smart, surprisingly original movie about a decent, average guy who just never had sex.<br /><br />Yes, the film is chock full o' sex jokes and vulgarity and the occasional hey-look-a-nipple!, but it's done much in the spirit of Bad Santa rather than Sorority Boys. All the characters are people you probably know in real life, redeemable friends who are just trying to hook a brother up and live their lives.<br /><br />I went in thinking this movie was going to be total crap, and I was very surprised. Yea, it's pretty over the top (c'mon, it's a movie about a 40 year old virgin!), but it's very smartly done.<br /><br />In the end, you're really pulling for this guy to get laid, which says a lot about the movie because honestly, did you really care if Ashton Kutcher found his car or not?\"\n",
            " b'When robot hordes start attacking major cities, who will stop the madman behind the attacks? Sky Captain!!! Jude Law plays Joe Sullivan, the ace of the skyways, tackling insurmountable odds along with his pesky reporter ex-girlfriend Polly Perkins (Gwyneth Paltrow) and former flight partner, Captain Franky Cook (Angelina Jolie).<br /><br />Sky Captain and the World of Tomorrow may look and feel like an exciting movie but it really is quite dull and underwhelming. The film\\'s running time is 106 minutes yet it feels so much longer because there is no substance in this movie. The visuals were great and the film did a nice job on that. However, there is nothing to support these wonderful visuals. The film lacks a story and interesting characters making the while thing quite dull and unnecessary. I blame director and writer Kerry Conran. He focuses too much on the visuals and spent little time on the actual story. The movie is like a girl with no personality, after awhile it kind of gets bland and tiring. Sky Captain represents a beautiful girl with no personality. It\\'s simply just another case of style over substance.<br /><br />The acting is surprisingly average and that\\'s not really their fault since they had very little to work with. The main reason I watched this movie is because of Angelina Jolie. However, the advertising is quite misleading and she is only in the film for about 30 minutes. Her performance is surprisingly bland as well. Jude Law gives an okay performance though you would expect a lot more from him. Gwyneth Paltrow was just average, nothing special at all. Ling Bai\\'s performance was the only one I really liked. She gives a pretty good performance as the mysterious woman and she was the only interesting character in the entire film.<br /><br />The movie is not a complete bust though. There were some \"wow\" and exciting scenes. There just weren\\'t enough of them. The film just doesn\\'t have that hook to really make it memorable. It was actually quite bland and it wasn\\'t very engaging at all. It\\'s too bad the film wasn\\'t very good since it had such a promising premise. In the end, Sky Captain is surprisingly below average and not really worth watching. Rating 4/10'\n",
            " b'Well, \"Cube\" (1997), Vincenzo\\'s first movie, was one of the most interesting and tricky ideas that I\\'ve ever seen when talking about movies. They had just one scenery, a bunch of actors and a plot. So, what made it so special were all the effective direction, great dialogs and a bizarre condition that characters had to deal like rats in a labyrinth. His second movie, \"Cypher\" (2002), was all about its story, but it wasn\\'t so good as \"Cube\" but here are the characters being tested like rats again.<br /><br />\"Nothing\" is something very interesting and gets Vincenzo coming back to his \\'Cube days\\', locking the characters once again in a very different space with no time once more playing with the characters like playing with rats in an experience room. But instead of a thriller sci-fi (even some of the promotional teasers and trailers erroneous seemed like that), \"Nothing\" is a loose and light comedy that for sure can be called a modern satire about our society and also about the intolerant world we\\'re living. Once again Vicenzo amaze us with a great idea into a so small kind of thing. 2 actors and a blinding white scenario, that\\'s all you got most part of time and you don\\'t need more than that. While \"Cube\" is a claustrophobic experience and \"Cypher\" confusing, \"Nothing\" is completely the opposite but at the same time also desperate.<br /><br />This movie proves once again that a smart idea means much more than just a millionaire budget. Of course that the movie fails sometimes, but its prime idea means a lot and offsets any flaws. There\\'s nothing more to be said about this movie because everything is a brilliant surprise and a totally different experience that I had in movies since \"Cube\".'\n",
            " b\"It starts slowly, showing the dreary lives of the two housewives who decide to rent a castle in Italy for the month of April, but don't give up on it. Nothing much happens, but the time passes exquisitely, and there are numerous sly jokes (my favorite is the carriage ride in the storm, which I find hilarious). The movie is wonderfully romantic in many senses of the word, the scenery is beautiful (as is Polly Walker), and the resolutions in the movie are very satisfying.<br /><br />The movie takes a couple of liberties with the book, the biggest being with the Arbuthnot/Briggs/Dester business, but I actually preferred the movie's version of this (it may be more sentimental, but I felt that it was more consistent with the tone of the story, and anyway I like sentiment when it's well done).<br /><br />An excellent movie, especially as a date movie during lousy weather.\"], shape=(32,), dtype=string)\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "H5-T_d75F0Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs in binary_1gram_train_ds:\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(len(inputs[0]))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdftnJQOGhd7",
        "outputId": "d3ac8e66-e748-42f8-95ca-8633a98e1060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[0]: tf.Tensor(\n",
            "[[1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]], shape=(32, 20000), dtype=float32)\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이진 유니그램 데이터셋의 출력 확인하기\n",
        "\n",
        "입력은 2만차원 (사전 크기), 32개씩 들어감\n",
        "\n",
        "유니그램 인코딩에서 \"the cat sat on the mat\" 문장을 표현하면,  \n",
        "[\"cat\", \"mat\", \"on\", \"sat\", \"the\"]"
      ],
      "metadata": {
        "id": "xWKTKompPdKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lkms_1kPbt8",
        "outputId": "157074df-d755-4a9d-9b4a-4e389d28a126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 생성 유틸리티"
      ],
      "metadata": {
        "id": "pfG_5m3uQr02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "xjjVUg0XPfYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이진 유니그램 모델 훈련하고 테스트하기"
      ],
      "metadata": {
        "id": "WAufaByoTyad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIozGv6FQt3j",
        "outputId": "518eb3a6-d709-426b-dea1-517784522847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 10s 8ms/step - loss: 0.4007 - accuracy: 0.8288 - val_loss: 0.2828 - val_accuracy: 0.8894\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2683 - accuracy: 0.9003 - val_loss: 0.2797 - val_accuracy: 0.8912\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2382 - accuracy: 0.9173 - val_loss: 0.2904 - val_accuracy: 0.8918\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2297 - accuracy: 0.9242 - val_loss: 0.3095 - val_accuracy: 0.8892\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2100 - accuracy: 0.9313 - val_loss: 0.3176 - val_accuracy: 0.8906\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2143 - accuracy: 0.9330 - val_loss: 0.3309 - val_accuracy: 0.8912\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9376 - val_loss: 0.3414 - val_accuracy: 0.8870\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2048 - accuracy: 0.9383 - val_loss: 0.3481 - val_accuracy: 0.8896\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1933 - accuracy: 0.9406 - val_loss: 0.3553 - val_accuracy: 0.8854\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1965 - accuracy: 0.9402 - val_loss: 0.3671 - val_accuracy: 0.8862\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2881 - accuracy: 0.8880\n",
            "테스트 정확도: 0.888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이진 인코딩을 사용한 바이그램"
      ],
      "metadata": {
        "id": "ypZnd6nST4Pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 바이그램을 반환하는 TextVectorization 층 만들기\n",
        "\n",
        "바이그램 인코딩에서 \"the cat sat on the mat\" 문장을 표현하면,  \n",
        "[\"cat\", \"mat\", \"on\", \"sat\", \"the\", \"the cat\", \"cat sat\", \"sat on\", \"on the\", \"the mat\"]"
      ],
      "metadata": {
        "id": "3IR2f__iT7JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,         # 여기에 지정하면 됨\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ],
      "metadata": {
        "id": "ojIURx35T1Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이진 바이그램 모델 훈련하고 테스트하기"
      ],
      "metadata": {
        "id": "ECFK52n9T_lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X2LPTRgT9M9",
        "outputId": "8080b5dc-47a4-427b-a27f-5cc21f3b798b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 7s 9ms/step - loss: 0.3860 - accuracy: 0.8391 - val_loss: 0.2658 - val_accuracy: 0.9026\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2481 - accuracy: 0.9128 - val_loss: 0.2655 - val_accuracy: 0.8984\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2107 - accuracy: 0.9319 - val_loss: 0.2797 - val_accuracy: 0.9002\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1896 - accuracy: 0.9399 - val_loss: 0.2972 - val_accuracy: 0.8998\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1832 - accuracy: 0.9456 - val_loss: 0.3072 - val_accuracy: 0.9008\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1720 - accuracy: 0.9507 - val_loss: 0.3274 - val_accuracy: 0.9010\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1711 - accuracy: 0.9514 - val_loss: 0.3516 - val_accuracy: 0.8992\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1631 - accuracy: 0.9546 - val_loss: 0.3640 - val_accuracy: 0.8982\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1588 - accuracy: 0.9577 - val_loss: 0.3655 - val_accuracy: 0.8978\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1640 - accuracy: 0.9564 - val_loss: 0.3841 - val_accuracy: 0.8966\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2706 - accuracy: 0.8999\n",
            "테스트 정확도: 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단어를 시퀀스로 처리하기: 시퀀스 모델 방식\n",
        "\n",
        "바이그램 예에서 보듯 순서도 중요함\n",
        "\n",
        "순서 기반의 특성을 수동으로 만드는 대신 이런 특성을 학습하도록 하는 것이 **시퀀스 모델**\n",
        "\n",
        "기존 모델과 다른점\n",
        "기존 모델은 문장 하나를 하나의 벡터(예: 멀티 핫 인코딩)으로 만들어서 그 벡터를 통채로 입력했다면, 시퀀스 모델은 단어 하나를 하나의 벡터로 만들고 이를 순차적으로 입력해서 최종 결과를 만들어냄"
      ],
      "metadata": {
        "id": "NviIrxMvURLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 다운로드"
      ],
      "metadata": {
        "id": "Af0N7-uLUTTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWJL3zLoUBxf",
        "outputId": "7dd0124b-7d88-43b9-b36b-c0e1a1ceaca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  32.2M      0  0:00:02  0:00:02 --:--:-- 32.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 준비"
      ],
      "metadata": {
        "id": "qW-8riRwUcRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib, shutil, random\n",
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    try:\n",
        "      os.makedirs(val_dir / category)\n",
        "    except:\n",
        "      pass\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv9agCpLUaal",
        "outputId": "d6045188-3464-459f-88f5-ce26f16f249e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 정수 시퀀스 데이터셋 준비하기\n",
        "\n",
        "가장 기본 - 하나의 단어를 원핫 인코딩 벡터로 바꿔서 하나씩 입력하기"
      ],
      "metadata": {
        "id": "uFdIDSpuUfte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 600      # 적당한 길이의 입력을 위해 600개보다 긴 리뷰의 뒷부분은 잘라버림\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "S6H9IYgTUeYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htFWP-raLSY8",
        "outputId": "42557fe7-6773-4cb4-d28f-310513a7037a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b'Russell, my fav, is gorgeous in this film. But more than that, the film covers a tremendous range of human passion and sorrow. Everything from marriage to homosexuality is addressed and respected. The film makes the viewer realize that tolerance of other humans provides the route to saving humanity. Fabulous love story between Lachlin and Lil. I replay their scenes over and over again. Anyone who has ever been in love will empathize with these people. All characters are cast and portrayed excellently.', shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 원-핫 인코딩된 벡터 시퀀스로 시퀀스 모델 만들기"
      ],
      "metadata": {
        "id": "RP5-ZtumUjJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")  # 입력은 정수 시퀀스\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)     # 정수를 20,000차원의 이진벡터로 인코딩\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded) # 양방향 LSTM 층을 추가\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # 마지막 분류층 추가\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ribAkvNPUhY8",
        "outputId": "882aeabc-5a0c-4ff6-9d02-7f9d8b9c1ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               5128448   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,128,513\n",
            "Trainable params: 5,128,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 첫 번째 시퀀스 모델 훈련하기"
      ],
      "metadata": {
        "id": "2efuR3pMUmPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2weHfklUk3t",
        "outputId": "d1fc98e3-962a-48c5-a65f-5d89705fb068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 165s 257ms/step - loss: 0.5574 - accuracy: 0.7119 - val_loss: 0.6301 - val_accuracy: 0.7600\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 163s 260ms/step - loss: 0.3607 - accuracy: 0.8630 - val_loss: 0.2945 - val_accuracy: 0.8870\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 162s 259ms/step - loss: 0.2841 - accuracy: 0.8981 - val_loss: 0.3198 - val_accuracy: 0.8758\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 162s 260ms/step - loss: 0.2549 - accuracy: 0.9119 - val_loss: 0.3180 - val_accuracy: 0.8818\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.2233 - accuracy: 0.9273 - val_loss: 0.2844 - val_accuracy: 0.8870\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 162s 258ms/step - loss: 0.1971 - accuracy: 0.9347 - val_loss: 0.3340 - val_accuracy: 0.8696\n",
            "Epoch 7/10\n",
            "172/625 [=======>......................] - ETA: 1:43 - loss: 0.1751 - accuracy: 0.9428"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련이 매우 느림\n",
        "\n",
        "- 입력크기가 너무 큼\n",
        "- 각 입력 샘플은 (600, 20000) 크기임 (단어당 20000, 길이 최대 600)\n",
        "- 하나의 영화 리뷰는 12000000 개의 값으로 이루어짐"
      ],
      "metadata": {
        "id": "6P6drwMoOrYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 안좋은 이유\n",
        "\n",
        "- 단어를 원핫 인코딩으로 벡터화 했기 때문  \n",
        "- 20000 짜리 벡터중 한 값만 1이고 나머지는 0"
      ],
      "metadata": {
        "id": "nSPBQZOJOd9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단어 임베딩 이해하기"
      ],
      "metadata": {
        "id": "j3ghchu8Upsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 임베딩 층으로 단어 임베딩 학습하기"
      ],
      "metadata": {
        "id": "-CpMESEVUryr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding 층 만들기\n"
      ],
      "metadata": {
        "id": "4-XI-GnRUtrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
      ],
      "metadata": {
        "id": "rw40GetyUoC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 밑바닥부터 훈련하는 Embedding 층을 사용한 모델"
      ],
      "metadata": {
        "id": "DqXkOsycUwyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_lstm.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "GfXsjHJmUvb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "속도가 빨라졌음\n",
        "- 이전에는 단어당 크기 20000 의 벡터였음\n",
        "- embedding 을 통해 단어당 256 개의 벡터를 사용\n",
        "- 기본모델보다 여전히 성능이 낮음 - 600개가 넘는 단어는 잘라버리기 때문? "
      ],
      "metadata": {
        "id": "VH_hyOEZ0oxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패딩과 마스킹 이해하기"
      ],
      "metadata": {
        "id": "Wf_ljV76U1zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 마스킹을 활성화한 Embedding 층 사용하기\n",
        "\n",
        "시퀀스의 길이가 600 이기 때문에 600보다 짧은 문장은 0으로 나머지를 채움\n",
        "\n",
        "0으로 된것도 계속 학습.. 0으로 된 것은 건너뛰도록 하는 것이 masking"
      ],
      "metadata": {
        "id": "oY0SC9HeU3ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(input_dim=10, output_dim=256, mask_zero=True)\n",
        "some_input = [\n",
        "    [4,3,2,1,0,0,0],\n",
        "    [5,4,3,2,1,0,0],\n",
        "    [2,1,0,0,0,0,0]\n",
        "]\n",
        "mask = embedding_layer.compute_mask(some_input)"
      ],
      "metadata": {
        "id": "zx4Wggzm1O58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNLdOOeP2JaT",
        "outputId": "fbbc6f55-6af6-461c-ea7b-bbc3d0a8707f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 7), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True, False, False, False],\n",
              "       [ True,  True,  True,  True,  True, False, False],\n",
              "       [ True,  True, False, False, False, False, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "masking 은 직접 작업하지 않고 옵션으로 주면 됨"
      ],
      "metadata": {
        "id": "a5IAiA9U2pMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs) # mask 를 사용하도록 하는 옵션\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_lstm_with_masking.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "e3kVh612Uzb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "약간의 성능 향상이 더 됨"
      ],
      "metadata": {
        "id": "pdEQJePE2jYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 훈련된 단어 임베딩 사용하기\n",
        "\n",
        "2014 년 영어 위키피디아 데이터셋에서 미리 학습\n",
        "\n",
        "- 822메가(압축)\n",
        "- 40만개의 단어\n",
        "- 100차원 임베딩 벡터"
      ],
      "metadata": {
        "id": "OVxXkLQWU-B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-SyhVncU5b2",
        "outputId": "caa425c3-c3d7-45d8-a642-ea5d18486d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-05 14:42:48--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-05 14:42:48--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-05 14:42:49--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-05 14:45:29 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GloVe 단어 임베딩 파일 파싱하기"
      ],
      "metadata": {
        "id": "dcpi4RbNVBKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"단어 벡터 개수: {len(embeddings_index)}\")"
      ],
      "metadata": {
        "id": "mLfEBlwIU_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index"
      ],
      "metadata": {
        "id": "JVFVuMs74HsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index.keys()"
      ],
      "metadata": {
        "id": "zV4e4_5l4Jsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in embeddings_index.items()[:10]:\n",
        "  print(f\"{key} {value}\")"
      ],
      "metadata": {
        "id": "cN92YHvl4M2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GloVe 단어 임베딩 행렬 준비하기"
      ],
      "metadata": {
        "id": "yONAGXPNVGHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()  # 기존의 사전에서 단어를 추출\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))  # 어휘 사전에 있는 단어와 인덱스를 매핑\n",
        "\n"
      ],
      "metadata": {
        "id": "q-9ekDCWVGzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))  # GloVe 로 갈아치울 빈 행렬 준비\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)     # glove 에서 word 의 vector 를 가져옴\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector            # 빈 행렬에 glove 에서 가져온 vector 를 지정"
      ],
      "metadata": {
        "id": "_Q-8uBN93z62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),   # 사전에 훈련된 임베딩을 로드\n",
        "    trainable=False,      # 임베딩은 값이 바뀌지 않도록 trainable = False 로 지정\n",
        "    mask_zero=True,\n",
        ")"
      ],
      "metadata": {
        "id": "w7hZfqavVIT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 사전 훈련된 임베딩을 사용하는 모델\n",
        "\n",
        "위에서 직접 학습한 256차원의 임베딩이 아니라 사전에 학습된 100 차원 짜리 GloVe 를 사용"
      ],
      "metadata": {
        "id": "UMXru6ByVKo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"테스트 정확도: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "5GLielcvVNZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서는 크게 도움이 되지 않았음\n",
        "\n",
        "원인\n",
        "- 임베딩을 직접 학습할 만큼 충분한 데이터셋이 있었음\n",
        "- 미리 학습된 GloVe 가 더 좋았다면?"
      ],
      "metadata": {
        "id": "XT-Hp1OC5gwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BoW model vs Sequence Model\n",
        "\n",
        "훈련 데이터에 있는 샘플 수와 샘플에 있는 평균 단어 개수 사이의 비율이 가이드라인이 될 수 있음\n",
        "\n",
        "샘플개수 / 평균샘플길이 \n",
        "- 1500 보다 크면 시퀀스 모델\n",
        "- 1500 보다 작으면 바이그램 모델\n",
        "\n",
        "IMDB 데이터의 경우 훈련 샘플개수 2만개, 평균 단어수 233개\n",
        "\n",
        "샘플개수 / 평균샘플길이 = 20000 / 233 = 85.8 < 1500\n",
        "- 바이그램 모델이 맞음\n",
        "\n",
        "절대적인 것은 아님"
      ],
      "metadata": {
        "id": "NVZtMg8U6dLA"
      }
    }
  ]
}