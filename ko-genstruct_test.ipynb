{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM3myRWD16HiDfPQqERnmK8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1076fb07f2b444e59fef5d4bc3c1650f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e31d3645c83422ab8f6197dbce5a68e",
              "IPY_MODEL_4dfbb02c4ad340f0a83fe8b1d7643b96",
              "IPY_MODEL_bea8b646eb934fdea7c49adbd7057f56"
            ],
            "layout": "IPY_MODEL_4f63ed79c8ab44b5abe5f6854d0c906f"
          }
        },
        "4e31d3645c83422ab8f6197dbce5a68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9cc748c9368445188988b7c4414487d",
            "placeholder": "​",
            "style": "IPY_MODEL_5fbb06cfdb1046dda15af7f6c72f7a95",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4dfbb02c4ad340f0a83fe8b1d7643b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b15041c80bd4cb183341a01f3a27c5a",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45b27f3a0aa64f86a5a9021471c906d9",
            "value": 4
          }
        },
        "bea8b646eb934fdea7c49adbd7057f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e76329821e64d94b088fcbe03c7b308",
            "placeholder": "​",
            "style": "IPY_MODEL_39bab4a0471d47c39802ec527196ac0b",
            "value": " 4/4 [00:05&lt;00:00,  1.14s/it]"
          }
        },
        "4f63ed79c8ab44b5abe5f6854d0c906f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cc748c9368445188988b7c4414487d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fbb06cfdb1046dda15af7f6c72f7a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b15041c80bd4cb183341a01f3a27c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b27f3a0aa64f86a5a9021471c906d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e76329821e64d94b088fcbe03c7b308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39bab4a0471d47c39802ec527196ac0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkwith7/aSSIST_ML/blob/main/ko-genstruct_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58v0coZ0RsF5",
        "outputId": "e20d6253-1b23-40fd-a35f-2483716f67f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 23 05:20:10 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              45W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ['HF_TOKEN']=\"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\""
      ],
      "metadata": {
        "id": "2V7o1RDESiZ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmM-GE5vTH3D",
        "outputId": "06042307-fad4-4dbd-c981-bafd918f9ecb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr57a1hPUn9G",
        "outputId": "3516addf-360e-4c57-d12f-ed309de3c140"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/peft\n",
            "  Cloning https://github.com/huggingface/peft to /tmp/pip-req-build-vlt2m_08\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-vlt2m_08\n",
            "  Resolved https://github.com/huggingface/peft to commit ba75bb14d115dfdff3294674d82d8097319ed74e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.2.dev0) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.2.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.2.dev0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.2.dev0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.2.dev0) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.2.dev0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.2.dev0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.11.2.dev0) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.11.2.dev0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.11.2.dev0) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.11.2.dev0) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.11.2.dev0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.2.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.2.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.2.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.2.dev0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.11.2.dev0) (1.3.0)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.11.2.dev0-py3-none-any.whl size=294483 sha256=8766bb241a2b6b76754db675e9001dec7a1b6ee6be36a7dc42222ab69de8a89c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wjl2bpbc/wheels/4c/16/67/1002a2d4daa822eff130e6d85b90051b75d2ce0d26b9448e4a\n",
            "Successfully built peft\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, peft\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 peft-0.11.2.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujb_YbivYCfZ",
        "outputId": "479d5e44-9320-41e1-cdfd-b39d8dd6f02b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adapter-transformers"
      ],
      "metadata": {
        "id": "sDc0JEv7Cj8E",
        "outputId": "96066ef0-4f3f-45d4-bf98-2a0fc1821bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adapter-transformers\n",
            "  Downloading adapter_transformers-4.0.0.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting adapters (from adapter-transformers)\n",
            "  Downloading adapters-0.2.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.0/263.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers~=4.40.2 (from adapters->adapter-transformers)\n",
            "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.40.2->adapters->adapter-transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.40.2->adapters->adapter-transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.40.2->adapters->adapter-transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.40.2->adapters->adapter-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.40.2->adapters->adapter-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.40.2->adapters->adapter-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.40.2->adapters->adapter-transformers) (2024.7.4)\n",
            "Building wheels for collected packages: adapter-transformers\n",
            "  Building wheel for adapter-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adapter-transformers: filename=adapter_transformers-4.0.0-py3-none-any.whl size=2633 sha256=59074cf26a9d9f14d3d74bba592dad7082ff854a1af0ecbddc750bf7815e4cd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/26/aa/b7f2a747658552164a7f8565a5d9592b7480e76cf69d353b48\n",
            "Successfully built adapter-transformers\n",
            "Installing collected packages: transformers, adapters, adapter-transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed adapter-transformers-4.0.0 adapters-0.2.2 transformers-4.40.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ac1ezvQyN_Fx"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
        "peft_model_id = \"iknow-lab/ko-genstruct-v0.1\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=\"auto\").eval()\n",
        "model.load_adapter(peft_model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "1076fb07f2b444e59fef5d4bc3c1650f",
            "4e31d3645c83422ab8f6197dbce5a68e",
            "4dfbb02c4ad340f0a83fe8b1d7643b96",
            "bea8b646eb934fdea7c49adbd7057f56",
            "4f63ed79c8ab44b5abe5f6854d0c906f",
            "b9cc748c9368445188988b7c4414487d",
            "5fbb06cfdb1046dda15af7f6c72f7a95",
            "2b15041c80bd4cb183341a01f3a27c5a",
            "45b27f3a0aa64f86a5a9021471c906d9",
            "3e76329821e64d94b088fcbe03c7b308",
            "39bab4a0471d47c39802ec527196ac0b"
          ]
        },
        "id": "liH8D6hJPEDc",
        "outputId": "6a2db3ee-c785-4f64-dee2-2df365ea17a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1076fb07f2b444e59fef5d4bc3c1650f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"아주대학교 학칙\"\n",
        "text = \"\"\"\n",
        "제1장 총칙\n",
        "제1조(목적) 이 학칙은 아주대학교(이하“본 대학교”라 한다)의 이념을 설정하고 이를 달성하는데 필요한 사항을 규정함을 목적으로 한다.\n",
        "제2조(대학이념) 본 대학교는 대한민국 교육의 근본이념에 입각하여 인간존중, 실사구시, 세계일가의 정신으로 국가 및 인류사회의 발전에 기여할 수 있는 유능한 인재를 양성하고 학술의 심오한 이론과 그 광범하고 정치한 응용방법을 연구하며 교육ㆍ연구의 능력과 시설을 활용하여 사회에 직접 봉사하는 것을 목표로 한다.\n",
        "제3조(정의) ①“학사과정”이라 함은 학사학위를 수여하기 위한 과정을 말한다.\n",
        "   ②“석사과정”이라 함은 석사학위를,“박사과정”이라 함은 박사학위를,“석ㆍ박사통합과정”이라 함은 학사에게 박사학위를 각각 수여하기 위한 과정을 말한다.\n",
        "   ③“대학원과정”이라 함은 본 대학교 일반대학원, 전문대학원 및 특수대학원에 설치된 석사과정, 박사과정 및 석ㆍ박사통합과정 모두를 말한다.\n",
        "   ④“학과간협동과정”이라 함은 대학원과정 안에 2개 이상의 학과가 공동으로 설치ㆍ운영하는 과정을 말한다. (개정 2013.7.5)\n",
        "   ⑤“학연산협동과정”이라 함은 대학원과정 안에 연구기관 또는 산업체와의 계약에 의하여 설치ㆍ운영하는 학ㆍ연ㆍ산, 학ㆍ연 또는 학ㆍ산 협동과정을 말한다.\n",
        "   ⑥“학ㆍ석사연계과정”이라 함은 본 대학교 학사과정과 일반대학원 석사과정을 연계하는 과정을 말한다. (신설 2008.5.21)\n",
        "   ⑦“특수학부”라 함은 대학에 소속되어 있지 않은 독립학부를 말한다. (개정 2008.5.21) (개정 2010.7.21)\n",
        "   ⑧ “전문과정”이라 함은 학사과정에서 대외 교육인증을 받기 위하여 운영하는 교육과정을 말한다. (신설 2011.8.11)\n",
        "제2장 조직\n",
        "제4조(기구) 본 대학교에 총장, 교무부총장, 의무부총장, 산학부총장, 대학, 일반대학원, 전문대학원, 특수대학원, 특수학부, 대학교본부, 부속기관, 연구기관, 지원기관, 아주대학교산학협력단, 의료원, 총장직속기구, 부총장직속기구 및 특별기구를 두며, 세부사항은 별표1과 같다. (개정 2007.3.26) (개정 2007.7.25) (개정 2007.9.9) (개정 2008.2.22) (개정 2008.12.16) (개정 2009.2.20) (개정 2009.4.2) (개정 2009.4.29) (개정 2009.7.27) (개정 2009.10.18) (개정 2009.12.7) (개정 2010.2.26) (개정 2010.7.21) (개정 2011.1.11) (개정 2011.8.11) (개정 2011.12.23) (개정 2012.5.10) (개정 2012.7.17) (개정 2012.11.19) (개정 2013.1.25) (개정 2013.5.1) (개정 2013.7.30) (개정 2013.12.31) (개정 2014.5.30) (개정 2014.6.30) (개정 2015.2.10) (개정 2015.05.18) (개정 2015.08.13.) (개정 2015.10.16) (개정 2016.1.8) (개정 2016.2.3) (개정 2016.3.24) (개정 2016.5.9) (개정 2016.8.23) (개정 2016.12.29) (개정 2017.2.13) (개정 2017.4.19) (개정 2017.7.14) (개정 2018.1.31) (개정 2018.5.11) (개정 2018.8.12) (개정 2019.01.15) (개정 2019.10.2) (개정 2020.  .  )\n",
        "제5조(총장) 총장은 교무를 통할하고 본 대학교를 대표한다.\n",
        "제6조(부총장) ① 교무부총장은 의무(醫務)와 산학협력 이외의 교무(校務)에 관하여, 의무부총장은 의무(醫務)에 관하여 산학부총장은 산학협력에 관하여 총장을 보좌하며, 각 부총장은 총장이 구체적으로 위임한 업무를 관장한다. (개정 2009.4.2) (개정 2015.10.16)\n",
        "   ② 총장이 궐위되거나 그 직무를 수행할 수 없는 사정이 있는 경우에는 이사장이 지명하는 부총장이 총장의 직무를 대행한다. (개정 2009.4.2)\n",
        "제7조(대학교본부) ① 대학교본부에 교무처, 연구정보처, 학생처, 총무처, 기획처, 입학처, 국제협력처를 둔다. (개정 2015.10.16) (개정 2017.4.19)\n",
        "   ② 각 처의 업무에 관하여는「아주대학교 직제규정」으로 정한다.\n",
        "제7조의2(평생학습중심대학추진본부) ①「아주대학교 직제규정」제5조 제10항에 의거 특별기구로 평생학습중심대학추진본부를 둔다. (신설 2009.7.27) (개정 2017.7.14)\n",
        "   ② 평생학습중심대학추진본부는 평생교육과 관련한 제반업무를 관할한다. (신설 2009.7.27)\n",
        "   ③ 평생학습중심대학추진본부 운영에 대해서는 총장이 따로 정한다. (신설 2009.7.27)\n",
        "제7조의3(기관생명윤리위원회) ①「아주대학교 직제규정」제5조 제10항에 의거 특별기구로 기관생명윤리위원회를 둔다. (신설 2013.7.30) (개정 2017.7.14)\n",
        "   ② 기관생명윤리위원회는 인간대상연구 및 인체유래물연구의 윤리와 안전을 심의하고 감독하는 업무를 관할한다. (신설 2013.7.30)\n",
        "   ③ 기관생명윤리위원회 운영에 대해서는 총장이 따로 정한다. (신설 2013.7.30)\"\"\""
      ],
      "metadata": {
        "id": "sQdjEXpdbBon"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_QA = \"\"\"당신은 시험문제 출제위원입니다. 다음 자료에 기반하여 전문가 수준의 시험문제를 출제할 것입니다. 자료를 바탕으로 지시사항에 맞는 결과물을 json 형식으로 반환해주세요.\n",
        "1. 생성한 문제는 실생활에서 사용하는 질문의 말투를 사용해야 합니다(~무엇인가요? ~작성해주세요. ~ 어떻게 해야하죠?)\n",
        "2. 먼저 고등학교 수준의 문제를 생성하고, 이를 전문가 수준으로 고난이도 문제로 향상해주세요. 각 문제는 반드시 제시된 자료를 바탕으로 만들어져야 합니다. 연관성이 적더라도, 창의적인 아이디어로 해당 자료를 활용하세요.\n",
        "3. 문제에는 답안 작성에 필요한 내용을 주어진 자료에서 추출해서 함께 제공해야합니다.\n",
        "4. 출제할 문제의 과목 후보는 다음과 같습니다: 글쓰기, 한국어, 영어, 수학, 사회과학, 과학, 역사 문화예술, 법, 도덕, 정치, 종교, 외국어, 경제, 경영, 의료, 공학, 인문학 등 - 후보에 없어도, 적절한 과목을 자유롭게 말할 수 있다.\n",
        "# 제목: {title}\n",
        "# 자료:\n",
        "{text}\"\"\"\n",
        "PROMPT_WRITING = \"\"\"당신은 글쓰기 시험문제 출제위원입니다. 다음 자료에 기반하여 전문가 수준의 시험문제를 출제할 것입니다. 자료를 바탕으로 지시사항에 맞는 결과물을 json 형식으로 반환해주세요.\n",
        "1. 생성한 문제는 실생활에서 사용하는 질문의 말투를 사용해야 합니다(~무엇인가요? ~작성해주세요. ~ 어떻게 해야하죠?)\n",
        "2. 먼저 고등학교 수준의 문제를 생성하고, 이를 전문가 수준으로 고난이도 문제로 향상해주세요. 각 문제는 반드시 제시된 자료를 바탕으로 만들어져야 합니다. 연관성이 적더라도, 창의적인 아이디어로 해당 자료를 활용하세요.\n",
        "3. 문제에는 글쓰기 작성에 필요한 내용을 주어진 자료에서 추출해서 함께 제공해야합니다.\n",
        "4. 출제할 문제의 주제 후보는 다음과 같습니다. 이 중에서 적절한 주제를 3가지 선택하세요: 이력서, 노래가사, 시 혹은 소설, 에세이, 극본, 시나리오, 여행일기, 여행계획서, 요리레시피, 해설, 자기소개서, 편지, 이메일, 리뷰 및 평가, 소셜 미디어 포스트, 일기, 청원서, 항의서, 쇼핑 리스트, 메모, 연구 논문 및 계획서, 비즈니스 보고서 및 게획서, 기술 문서, 발표자료, 계약서 혹은 법률 문서, 편집 및 출판 문서, 광고 카피라이트, 웹 콘텐츠, 뉴스레터, 연설문, 자기계발서, 분석보고서, 기획안, 제안서\n",
        "# 제목: {title}\n",
        "# 자료:\n",
        "{text}\"\"\""
      ],
      "metadata": {
        "id": "OGRmN_QibPLn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_question(title, text, is_writing: bool = False):\n",
        "    prompt=PROMPT_WRITING if is_writing else PROMPT_QA\n",
        "    prompt = prompt.format(title=title, text=text)\n",
        "\n",
        "    prompt = [{\"content\": prompt, \"role\": \"user\"}]\n",
        "    inputs = tokenizer.apply_chat_template(prompt, return_tensors=\"pt\", add_generation_prompt=True, tokenize=False)\n",
        "    inputs = inputs.strip() + \"\\n\\n```json\\n{\\n  \\\"topic\\\":\"\n",
        "    inputs = tokenizer.encode(inputs, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(input_ids=inputs, max_new_tokens=256, do_sample=True, early_stopping=True, eos_token_id=128009, temperature=1.0)\n",
        "    question = tokenizer.decode(outputs[0, inputs.shape[1]:], skip_special_tokens=False)\n",
        "    return question\n",
        "print(\"Question generation test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asT_5EyfbRTH",
        "outputId": "e89dd052-b1f6-4580-857d-aceda41301ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question generation test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "    question = generate_question(title, text)\n",
        "    print(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SubV_dOVbf8n",
        "outputId": "3edb9e58-3ddd-461d-93fa-0dbe4ac61ed5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"대학원과정\",\n",
            "  \"question\": \"대학원과정의 종류는 무엇이며, 각 과정에 대해 설명해주세요.\",\n",
            "  \"hard_questions\": [\n",
            "    \"학사과정, 석사과정, 박사과정, 석ㆍ박사통합과정, 대학원과정, 학ㆍ석사연계과정, 전문과정의 차이와 교육과정에 대해 상세히 설명해주세요.\",\n",
            "    \"대학원과정과 대학의 협력과정에 대해 어떤 협력방식을 제안하고, 대학원과정이 대학의 학술분야 발전에 미치는 영향에 대해 논하세요.\",\n",
            "    \"대학원과정 중 특수학부의 역할과 기능에 대해 설명하고, 학부와의 협력 방식에 대해 제안해주세요.\"\n",
            "  ]\n",
            "}\n",
            "```<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"대학 조직\",\n",
            "  \"question\": \"대학 내에서 각각의 기구의 역할과 책임은 무엇인가요?\",\n",
            "  \"hard_questions\": [\n",
            "    \"대학 내부 조직의 구체적인 내규 및 역할을 설명하고, 조직 내에서 각 부처가 어떻게 협력하고 있는지에 대해 예시를 들어 설명해주세요.\",\n",
            "    \"평생학습중심대학추진본부와 기관생명윤리위원회의 각각의 업무를 비교하고, 이러한 기구들이 대학의 미래 전략에 미치는 영향을 논하세요.\",\n",
            "    \"대학 조직의 효율성을 높이기 위한 방안을 제시하고, 이러한 제안이 대학 내부의 기능에 미치는 영향을 설명해주세요.\"\n",
            "  ]\n",
            "}\n",
            "```<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"대학원과정\",\n",
            "  \"question\": \"대학원과정에 대해 설명해주세요.\",\n",
            "  \"hard_questions\": [\n",
            "    \"대학원과정이란 어떤 과정을 말하며, 각각 어떤 학사학위가 수여되는지 설명해주세요.\",\n",
            "    \"대학원과정의 특수학부와 전문과정에 대해 각각 설명해주세요.\",\n",
            "    \"대학원과정의 종류 중 학연산협동과정이 무엇인지 설명하고, 이를 통해 이루어지는 연구의 특징을 설명해주세요.\"\n",
            "  ]\n",
            "}\n",
            "```<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"학칙\",\n",
            "  \"question\": \"대학원과 학사과정의 차이점은 무엇인가요?\",\n",
            "  \"hard_questions\": [\n",
            "    \"학사과정과 석사과정의 차이점을 설명해주세요.\",\n",
            "    \"대학원과 석사과정, 박사과정의 구분에 대해 상세히 설명해주세요.\",\n",
            "    \"학ㆍ석사연계과정과 학ㆍ석사통합과정의 차이점은 무엇인가요?\"\n",
            "  ]\n",
            "}\n",
            "```<|eot_id|>\n",
            " \"사회과학\",\n",
            "  \"question\": \"아주대학교의 대학원과정에 대해 설명해주세요.\",\n",
            "  \"hard_questions\": [\n",
            "    \"대학원과정의 구성과 각 과정의 차이점을 자세히 설명해주세요.\",\n",
            "    \"학연산협동과정과 학ㆍ석사연계과정의 차이점을 비교하고, 각 과정의 중요성을 설명해주세요.\",\n",
            "    \"대학생들이 대학원과정에 입학하기 위해 고려해야 할 요소는 무엇인가요?\"\n",
            "  ]\n",
            "}\n",
            "```<|eot_id|>\n"
          ]
        }
      ]
    }
  ]
}